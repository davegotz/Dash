<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_79) on Fri Feb 26 20:48:40 PST 2016 -->
<title>SQLContext</title>
<meta name="date" content="2016-02-26">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="SQLContext";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/SaveMode.html" title="enum in org.apache.spark.sql"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/SQLContext.html" target="_top">Frames</a></li>
<li><a href="SQLContext.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql</div>
<h2 title="Class SQLContext" class="title">Class SQLContext</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.sql.SQLContext</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable, <a href="../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dd>
</dl>
<dl>
<dt>Direct Known Subclasses:</dt>
<dd><a href="../../../../org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="strong">SQLContext</span>
extends java.lang.Object
implements <a href="../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a>, scala.Serializable</pre>
<div class="block">The entry point for working with structured data (rows and columns) in Spark.  Allows the
 creation of <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a> objects as well as the execution of SQL queries.
 <p></div>
<dl><dt><span class="strong">Since:</span></dt>
  <dd>1.0.0</dd>
<dt><span class="strong">See Also:</span></dt><dd><a href="../../../../serialized-form.html#org.apache.spark.sql.SQLContext">Serialized Form</a></dd></dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested_class_summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Nested Class Summary table, listing nested classes, and an explanation">
<caption><span>Nested Classes</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Class and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>class&nbsp;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql">SQLContext.implicits$</a></strong></code>
<div class="block">:: Experimental ::
 (Scala-specific) Implicit methods available in Scala for converting
 common Scala objects into <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a>s.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected class&nbsp;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.QueryExecution.html" title="class in org.apache.spark.sql">SQLContext.QueryExecution</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected class&nbsp;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.SparkPlanner.html" title="class in org.apache.spark.sql">SQLContext.SparkPlanner</a></strong></code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#SQLContext(org.apache.spark.api.java.JavaSparkContext)">SQLContext</a></strong>(<a href="../../../../org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a>&nbsp;sparkContext)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colOne"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#SQLContext(org.apache.spark.SparkContext)">SQLContext</a></strong>(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sparkContext)</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#addJar(java.lang.String)">addJar</a></strong>(java.lang.String&nbsp;path)</code>
<div class="block">Add a jar to SQLContext</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.apache.spark.sql.catalyst.analysis.Analyzer</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#analyzer()">analyzer</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#applySchema(org.apache.spark.api.java.JavaRDD,%20java.lang.Class)">applySchema</a></strong>(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;?&gt;&nbsp;rdd,
           java.lang.Class&lt;?&gt;&nbsp;beanClass)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#applySchema(org.apache.spark.api.java.JavaRDD,%20org.apache.spark.sql.types.StructType)">applySchema</a></strong>(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rowRDD,
           <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#applySchema(org.apache.spark.rdd.RDD,%20java.lang.Class)">applySchema</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;?&gt;&nbsp;rdd,
           java.lang.Class&lt;?&gt;&nbsp;beanClass)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#applySchema(org.apache.spark.rdd.RDD,%20org.apache.spark.sql.types.StructType)">applySchema</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rowRDD,
           <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#applySchemaToPythonRDD(org.apache.spark.rdd.RDD,%20java.lang.String)">applySchemaToPythonRDD</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.Object[]&gt;&nbsp;rdd,
                      java.lang.String&nbsp;schemaString)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#applySchemaToPythonRDD(org.apache.spark.rdd.RDD,%20org.apache.spark.sql.types.StructType)">applySchemaToPythonRDD</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.Object[]&gt;&nbsp;rdd,
                      <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#baseRelationToDataFrame(org.apache.spark.sql.sources.BaseRelation)">baseRelationToDataFrame</a></strong>(<a href="../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</a>&nbsp;baseRelation)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.apache.spark.sql.execution.CacheManager</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#cacheManager()">cacheManager</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#cacheTable(java.lang.String)">cacheTable</a></strong>(java.lang.String&nbsp;tableName)</code>
<div class="block">Caches the specified table in-memory.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.apache.spark.sql.catalyst.analysis.Catalog</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#catalog()">catalog</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#clearActive()">clearActive</a></strong>()</code>
<div class="block">Clears the active SQLContext for current thread.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#clearCache()">clearCache</a></strong>()</code>
<div class="block">Removes all cached tables from the in-memory cache.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected org.apache.spark.sql.SQLConf</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#conf()">conf</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(org.apache.spark.api.java.JavaRDD,%20java.lang.Class)">createDataFrame</a></strong>(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;?&gt;&nbsp;rdd,
               java.lang.Class&lt;?&gt;&nbsp;beanClass)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(org.apache.spark.api.java.JavaRDD,%20org.apache.spark.sql.types.StructType)">createDataFrame</a></strong>(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rowRDD,
               <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(java.util.List,%20java.lang.Class)">createDataFrame</a></strong>(java.util.List&lt;?&gt;&nbsp;data,
               java.lang.Class&lt;?&gt;&nbsp;beanClass)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(java.util.List,%20org.apache.spark.sql.types.StructType)">createDataFrame</a></strong>(java.util.List&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rows,
               <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(org.apache.spark.rdd.RDD,%20java.lang.Class)">createDataFrame</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;?&gt;&nbsp;rdd,
               java.lang.Class&lt;?&gt;&nbsp;beanClass)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;A extends scala.Product&gt;&nbsp;<br><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(org.apache.spark.rdd.RDD,%20scala.reflect.api.TypeTags.TypeTag)">createDataFrame</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;A&gt;&nbsp;rdd,
               scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$1)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(org.apache.spark.rdd.RDD,%20org.apache.spark.sql.types.StructType)">createDataFrame</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rowRDD,
               <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;A extends scala.Product&gt;&nbsp;<br><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(scala.collection.Seq,%20scala.reflect.api.TypeTags.TypeTag)">createDataFrame</a></strong>(scala.collection.Seq&lt;A&gt;&nbsp;data,
               scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$2)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataset(java.util.List,%20org.apache.spark.sql.Encoder)">createDataset</a></strong>(java.util.List&lt;T&gt;&nbsp;data,
             <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$5)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataset(org.apache.spark.rdd.RDD,%20org.apache.spark.sql.Encoder)">createDataset</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;data,
             <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$4)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataset(scala.collection.Seq,%20org.apache.spark.sql.Encoder)">createDataset</a></strong>(scala.collection.Seq&lt;T&gt;&nbsp;data,
             <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$3)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String,%20java.lang.String)">createExternalTable</a></strong>(java.lang.String&nbsp;tableName,
                   java.lang.String&nbsp;path)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String,%20java.lang.String,%20java.util.Map)">createExternalTable</a></strong>(java.lang.String&nbsp;tableName,
                   java.lang.String&nbsp;source,
                   java.util.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String,%20java.lang.String,%20scala.collection.immutable.Map)">createExternalTable</a></strong>(java.lang.String&nbsp;tableName,
                   java.lang.String&nbsp;source,
                   scala.collection.immutable.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String,%20java.lang.String,%20java.lang.String)">createExternalTable</a></strong>(java.lang.String&nbsp;tableName,
                   java.lang.String&nbsp;path,
                   java.lang.String&nbsp;source)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String,%20java.lang.String,%20org.apache.spark.sql.types.StructType,%20java.util.Map)">createExternalTable</a></strong>(java.lang.String&nbsp;tableName,
                   java.lang.String&nbsp;source,
                   <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema,
                   java.util.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String,%20java.lang.String,%20org.apache.spark.sql.types.StructType,%20scala.collection.immutable.Map)">createExternalTable</a></strong>(java.lang.String&nbsp;tableName,
                   java.lang.String&nbsp;source,
                   <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema,
                   scala.collection.immutable.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected org.apache.spark.sql.execution.datasources.DDLParser</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#ddlParser()">ddlParser</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected java.lang.String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#dialectClassName()">dialectClassName</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#dropTempTable(java.lang.String)">dropTempTable</a></strong>(java.lang.String&nbsp;tableName)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#emptyDataFrame()">emptyDataFrame</a></strong>()</code>
<div class="block">:: Experimental ::
 Returns a <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a> with no rows or columns.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.InternalRow&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#emptyResult()">emptyResult</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.apache.spark.sql.execution.QueryExecution</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#executePlan(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">executePlan</a></strong>(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;plan)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected org.apache.spark.sql.execution.QueryExecution</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#executeSql(java.lang.String)">executeSql</a></strong>(java.lang.String&nbsp;sql)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/ExperimentalMethods.html" title="class in org.apache.spark.sql">ExperimentalMethods</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#experimental()">experimental</a></strong>()</code>
<div class="block">:: Experimental ::
 A collection of methods that are considered experimental, but can be used to hook into
 the query planner for advanced functionality.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected org.apache.spark.sql.catalyst.analysis.FunctionRegistry</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#functionRegistry()">functionRegistry</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>scala.collection.immutable.Map&lt;java.lang.String,java.lang.String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#getAllConfs()">getAllConfs</a></strong>()</code>
<div class="block">Return all the configuration properties that have been set (i.e.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.lang.String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#getConf(java.lang.String)">getConf</a></strong>(java.lang.String&nbsp;key)</code>
<div class="block">Return the value of Spark SQL configuration property for the given key.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.lang.String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#getConf(java.lang.String,%20java.lang.String)">getConf</a></strong>(java.lang.String&nbsp;key,
       java.lang.String&nbsp;defaultValue)</code>
<div class="block">Return the value of Spark SQL configuration property for the given key.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#getOrCreate(org.apache.spark.SparkContext)">getOrCreate</a></strong>(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sparkContext)</code>
<div class="block">Get the singleton SQLContext if it exists or create a new one using the given SparkContext.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.AttributeReference&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#getSchema(java.lang.Class)">getSchema</a></strong>(java.lang.Class&lt;?&gt;&nbsp;beanClass)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected org.apache.spark.sql.catalyst.ParserDialect</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#getSQLDialect()">getSQLDialect</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql">SQLContext.implicits$</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#implicits()">implicits</a></strong>()</code>
<div class="block">Accessor for nested Scala object</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#isCached(java.lang.String)">isCached</a></strong>(java.lang.String&nbsp;tableName)</code>
<div class="block">Returns true if the table is currently cached in-memory.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#isRootContext()">isRootContext</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jdbc(java.lang.String,%20java.lang.String)">jdbc</a></strong>(java.lang.String&nbsp;url,
    java.lang.String&nbsp;table)</code>
<div class="block"><strong>Deprecated.</strong>&nbsp;
<div class="block"><i>As of 1.4.0, replaced by <code>read().jdbc()</code>. This will be removed in Spark 2.0.</i></div>
</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jdbc(java.lang.String,%20java.lang.String,%20java.lang.String[])">jdbc</a></strong>(java.lang.String&nbsp;url,
    java.lang.String&nbsp;table,
    java.lang.String[]&nbsp;theParts)</code>
<div class="block"><strong>Deprecated.</strong>&nbsp;
<div class="block"><i>As of 1.4.0, replaced by <code>read().jdbc()</code>. This will be removed in Spark 2.0.</i></div>
</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jdbc(java.lang.String,%20java.lang.String,%20java.lang.String,%20long,%20long,%20int)">jdbc</a></strong>(java.lang.String&nbsp;url,
    java.lang.String&nbsp;table,
    java.lang.String&nbsp;columnName,
    long&nbsp;lowerBound,
    long&nbsp;upperBound,
    int&nbsp;numPartitions)</code>
<div class="block"><strong>Deprecated.</strong>&nbsp;
<div class="block"><i>As of 1.4.0, replaced by <code>read().jdbc()</code>. This will be removed in Spark 2.0.</i></div>
</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String)">jsonFile</a></strong>(java.lang.String&nbsp;path)</code>
<div class="block"><strong>Deprecated.</strong>&nbsp;
<div class="block"><i>As of 1.4.0, replaced by <code>read().json()</code>. This will be removed in Spark 2.0.</i></div>
</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String,%20double)">jsonFile</a></strong>(java.lang.String&nbsp;path,
        double&nbsp;samplingRatio)</code>
<div class="block"><strong>Deprecated.</strong>&nbsp;
<div class="block"><i>As of 1.4.0, replaced by <code>read().json()</code>. This will be removed in Spark 2.0.</i></div>
</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String,%20org.apache.spark.sql.types.StructType)">jsonFile</a></strong>(java.lang.String&nbsp;path,
        <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</code>
<div class="block"><strong>Deprecated.</strong>&nbsp;
<div class="block"><i>As of 1.4.0, replaced by <code>read().json()</code>. This will be removed in Spark 2.0.</i></div>
</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.api.java.JavaRDD)">jsonRDD</a></strong>(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;java.lang.String&gt;&nbsp;json)</code>
<div class="block"><strong>Deprecated.</strong>&nbsp;
<div class="block"><i>As of 1.4.0, replaced by <code>read().json()</code>. This will be removed in Spark 2.0.</i></div>
</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.api.java.JavaRDD,%20double)">jsonRDD</a></strong>(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;java.lang.String&gt;&nbsp;json,
       double&nbsp;samplingRatio)</code>
<div class="block"><strong>Deprecated.</strong>&nbsp;
<div class="block"><i>As of 1.4.0, replaced by <code>read().json()</code>. This will be removed in Spark 2.0.</i></div>
</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.api.java.JavaRDD,%20org.apache.spark.sql.types.StructType)">jsonRDD</a></strong>(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;java.lang.String&gt;&nbsp;json,
       <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</code>
<div class="block"><strong>Deprecated.</strong>&nbsp;
<div class="block"><i>As of 1.4.0, replaced by <code>read().json()</code>. This will be removed in Spark 2.0.</i></div>
</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD)">jsonRDD</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.String&gt;&nbsp;json)</code>
<div class="block"><strong>Deprecated.</strong>&nbsp;
<div class="block"><i>As of 1.4.0, replaced by <code>read().json()</code>. This will be removed in Spark 2.0.</i></div>
</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD,%20double)">jsonRDD</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.String&gt;&nbsp;json,
       double&nbsp;samplingRatio)</code>
<div class="block"><strong>Deprecated.</strong>&nbsp;
<div class="block"><i>As of 1.4.0, replaced by <code>read().json()</code>. This will be removed in Spark 2.0.</i></div>
</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD,%20org.apache.spark.sql.types.StructType)">jsonRDD</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.String&gt;&nbsp;json,
       <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</code>
<div class="block"><strong>Deprecated.</strong>&nbsp;
<div class="block"><i>As of 1.4.0, replaced by <code>read().json()</code>. This will be removed in Spark 2.0.</i></div>
</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.spark.sql.execution.ui.SQLListener</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#listener()">listener</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/util/ExecutionListenerManager.html" title="class in org.apache.spark.sql.util">ExecutionListenerManager</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#listenerManager()">listenerManager</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#load(java.lang.String)">load</a></strong>(java.lang.String&nbsp;path)</code>
<div class="block"><strong>Deprecated.</strong>&nbsp;
<div class="block"><i>As of 1.4.0, replaced by <code>read().load(path)</code>. This will be removed in Spark 2.0.</i></div>
</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#load(java.lang.String,%20java.util.Map)">load</a></strong>(java.lang.String&nbsp;source,
    java.util.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</code>
<div class="block"><strong>Deprecated.</strong>&nbsp;
<div class="block"><i>As of 1.4.0, replaced by <code>read().format(source).options(options).load()</code>.
             This will be removed in Spark 2.0.</i></div>
</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#load(java.lang.String,%20scala.collection.immutable.Map)">load</a></strong>(java.lang.String&nbsp;source,
    scala.collection.immutable.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</code>
<div class="block"><strong>Deprecated.</strong>&nbsp;
<div class="block"><i>As of 1.4.0, replaced by <code>read().format(source).options(options).load()</code>.</i></div>
</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#load(java.lang.String,%20java.lang.String)">load</a></strong>(java.lang.String&nbsp;path,
    java.lang.String&nbsp;source)</code>
<div class="block"><strong>Deprecated.</strong>&nbsp;
<div class="block"><i>As of 1.4.0, replaced by <code>read().format(source).load(path)</code>.
             This will be removed in Spark 2.0.</i></div>
</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#load(java.lang.String,%20org.apache.spark.sql.types.StructType,%20java.util.Map)">load</a></strong>(java.lang.String&nbsp;source,
    <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema,
    java.util.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</code>
<div class="block"><strong>Deprecated.</strong>&nbsp;
<div class="block"><i>As of 1.4.0, replaced by
            <code>read().format(source).schema(schema).options(options).load()</code>.</i></div>
</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#load(java.lang.String,%20org.apache.spark.sql.types.StructType,%20scala.collection.immutable.Map)">load</a></strong>(java.lang.String&nbsp;source,
    <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema,
    scala.collection.immutable.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</code>
<div class="block"><strong>Deprecated.</strong>&nbsp;
<div class="block"><i>As of 1.4.0, replaced by
            <code>read().format(source).schema(schema).options(options).load()</code>.</i></div>
</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#newSession()">newSession</a></strong>()</code>
<div class="block">Returns a SQLContext as new session, with separated SQL configurations, temporary tables,
 registered functions, but sharing the same SparkContext, CacheManager, SQLListener and SQLTab.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.apache.spark.sql.catalyst.optimizer.Optimizer</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#optimizer()">optimizer</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#parquetFile(scala.collection.Seq)">parquetFile</a></strong>(scala.collection.Seq&lt;java.lang.String&gt;&nbsp;paths)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#parquetFile(java.lang.String...)">parquetFile</a></strong>(java.lang.String...&nbsp;paths)</code>
<div class="block"><strong>Deprecated.</strong>&nbsp;
<div class="block"><i>As of 1.4.0, replaced by <code>read().parquet()</code>. This will be removed in Spark 2.0.</i></div>
</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#parseDataType(java.lang.String)">parseDataType</a></strong>(java.lang.String&nbsp;dataTypeString)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.apache.spark.sql.catalyst.plans.logical.LogicalPlan</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#parseSql(java.lang.String)">parseSql</a></strong>(java.lang.String&nbsp;sql)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected org.apache.spark.sql.execution.SparkPlanner</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#planner()">planner</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.apache.spark.sql.catalyst.rules.RuleExecutor&lt;org.apache.spark.sql.execution.SparkPlan&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#prepareForExecution()">prepareForExecution</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#range(long)">range</a></strong>(long&nbsp;end)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#range(long,%20long)">range</a></strong>(long&nbsp;start,
     long&nbsp;end)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#range(long,%20long,%20long,%20int)">range</a></strong>(long&nbsp;start,
     long&nbsp;end,
     long&nbsp;step,
     int&nbsp;numPartitions)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#read()">read</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#setActive(org.apache.spark.sql.SQLContext)">setActive</a></strong>(<a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;sqlContext)</code>
<div class="block">Changes the SQLContext that will be returned in this thread and its children when
 SQLContext.getOrCreate() is called.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#setConf(java.util.Properties)">setConf</a></strong>(java.util.Properties&nbsp;props)</code>
<div class="block">Set Spark SQL configuration properties.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#setConf(java.lang.String,%20java.lang.String)">setConf</a></strong>(java.lang.String&nbsp;key,
       java.lang.String&nbsp;value)</code>
<div class="block">Set the given Spark SQL configuration property.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#sparkContext()">sparkContext</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#sql(java.lang.String)">sql</a></strong>(java.lang.String&nbsp;sqlText)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.apache.spark.sql.execution.SparkSQLParser</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#sqlParser()">sqlParser</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#table(java.lang.String)">table</a></strong>(java.lang.String&nbsp;tableName)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.lang.String[]</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#tableNames()">tableNames</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.lang.String[]</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#tableNames(java.lang.String)">tableNames</a></strong>(java.lang.String&nbsp;databaseName)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#tables()">tables</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#tables(java.lang.String)">tables</a></strong>(java.lang.String&nbsp;databaseName)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#udf()">udf</a></strong>()</code>
<div class="block">A collection of methods for registering user-defined functions (UDF).</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#uncacheTable(java.lang.String)">uncacheTable</a></strong>(java.lang.String&nbsp;tableName)</code>
<div class="block">Removes the specified table from the in-memory cache.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.Logging">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.<a href="../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></h3>
<code><a href="../../../../org/apache/spark/Logging.html#initializeIfNecessary()">initializeIfNecessary</a>, <a href="../../../../org/apache/spark/Logging.html#initializeLogging()">initializeLogging</a>, <a href="../../../../org/apache/spark/Logging.html#isTraceEnabled()">isTraceEnabled</a>, <a href="../../../../org/apache/spark/Logging.html#log_()">log_</a>, <a href="../../../../org/apache/spark/Logging.html#log()">log</a>, <a href="../../../../org/apache/spark/Logging.html#logDebug(scala.Function0)">logDebug</a>, <a href="../../../../org/apache/spark/Logging.html#logDebug(scala.Function0,%20java.lang.Throwable)">logDebug</a>, <a href="../../../../org/apache/spark/Logging.html#logError(scala.Function0)">logError</a>, <a href="../../../../org/apache/spark/Logging.html#logError(scala.Function0,%20java.lang.Throwable)">logError</a>, <a href="../../../../org/apache/spark/Logging.html#logInfo(scala.Function0)">logInfo</a>, <a href="../../../../org/apache/spark/Logging.html#logInfo(scala.Function0,%20java.lang.Throwable)">logInfo</a>, <a href="../../../../org/apache/spark/Logging.html#logName()">logName</a>, <a href="../../../../org/apache/spark/Logging.html#logTrace(scala.Function0)">logTrace</a>, <a href="../../../../org/apache/spark/Logging.html#logTrace(scala.Function0,%20java.lang.Throwable)">logTrace</a>, <a href="../../../../org/apache/spark/Logging.html#logWarning(scala.Function0)">logWarning</a>, <a href="../../../../org/apache/spark/Logging.html#logWarning(scala.Function0,%20java.lang.Throwable)">logWarning</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="SQLContext(org.apache.spark.SparkContext)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>SQLContext</h4>
<pre>public&nbsp;SQLContext(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sparkContext)</pre>
</li>
</ul>
<a name="SQLContext(org.apache.spark.api.java.JavaSparkContext)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>SQLContext</h4>
<pre>public&nbsp;SQLContext(<a href="../../../../org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a>&nbsp;sparkContext)</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="getOrCreate(org.apache.spark.SparkContext)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getOrCreate</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;getOrCreate(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sparkContext)</pre>
<div class="block">Get the singleton SQLContext if it exists or create a new one using the given SparkContext.
 <p>
 This function can be used to create a singleton SQLContext object that can be shared across
 the JVM.
 <p>
 If there is an active SQLContext for current thread, it will be returned instead of the global
 one.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>sparkContext</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.5.0</dd></dl>
</li>
</ul>
<a name="setActive(org.apache.spark.sql.SQLContext)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setActive</h4>
<pre>public static&nbsp;void&nbsp;setActive(<a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;sqlContext)</pre>
<div class="block">Changes the SQLContext that will be returned in this thread and its children when
 SQLContext.getOrCreate() is called. This can be used to ensure that a given thread receives
 a SQLContext with an isolated session, instead of the global (first created) context.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>sqlContext</code> - (undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="clearActive()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>clearActive</h4>
<pre>public static&nbsp;void&nbsp;clearActive()</pre>
<div class="block">Clears the active SQLContext for current thread. Subsequent calls to getOrCreate will
 return the first created context instead of a thread-local override.
 <p></div>
<dl><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="parquetFile(java.lang.String...)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parquetFile</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;parquetFile(java.lang.String...&nbsp;paths)</pre>
<div class="block"><span class="strong">Deprecated.</span>&nbsp;<i>As of 1.4.0, replaced by <code>read().parquet()</code>. This will be removed in Spark 2.0.</i></div>
<div class="block">Loads a Parquet file, returning the result as a <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a>. This function returns an empty
 <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a> if no paths are passed in.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>paths</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="sparkContext()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sparkContext</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sparkContext()</pre>
</li>
</ul>
<a name="cacheManager()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cacheManager</h4>
<pre>protected&nbsp;org.apache.spark.sql.execution.CacheManager&nbsp;cacheManager()</pre>
</li>
</ul>
<a name="listener()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>listener</h4>
<pre>public&nbsp;org.apache.spark.sql.execution.ui.SQLListener&nbsp;listener()</pre>
</li>
</ul>
<a name="isRootContext()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isRootContext</h4>
<pre>public&nbsp;boolean&nbsp;isRootContext()</pre>
</li>
</ul>
<a name="newSession()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>newSession</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;newSession()</pre>
<div class="block">Returns a SQLContext as new session, with separated SQL configurations, temporary tables,
 registered functions, but sharing the same SparkContext, CacheManager, SQLListener and SQLTab.
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="conf()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>conf</h4>
<pre>protected&nbsp;org.apache.spark.sql.SQLConf&nbsp;conf()</pre>
<dl><dt><span class="strong">Returns:</span></dt><dd>Spark SQL configuration</dd></dl>
</li>
</ul>
<a name="setConf(java.util.Properties)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setConf</h4>
<pre>public&nbsp;void&nbsp;setConf(java.util.Properties&nbsp;props)</pre>
<div class="block">Set Spark SQL configuration properties.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>props</code> - (undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.0.0</dd></dl>
</li>
</ul>
<a name="setConf(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setConf</h4>
<pre>public&nbsp;void&nbsp;setConf(java.lang.String&nbsp;key,
           java.lang.String&nbsp;value)</pre>
<div class="block">Set the given Spark SQL configuration property.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>key</code> - (undocumented)</dd><dd><code>value</code> - (undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.0.0</dd></dl>
</li>
</ul>
<a name="getConf(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getConf</h4>
<pre>public&nbsp;java.lang.String&nbsp;getConf(java.lang.String&nbsp;key)</pre>
<div class="block">Return the value of Spark SQL configuration property for the given key.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>key</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.0.0</dd></dl>
</li>
</ul>
<a name="getConf(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getConf</h4>
<pre>public&nbsp;java.lang.String&nbsp;getConf(java.lang.String&nbsp;key,
                       java.lang.String&nbsp;defaultValue)</pre>
<div class="block">Return the value of Spark SQL configuration property for the given key. If the key is not set
 yet, return <code>defaultValue</code>.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>key</code> - (undocumented)</dd><dd><code>defaultValue</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.0.0</dd></dl>
</li>
</ul>
<a name="getAllConfs()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getAllConfs</h4>
<pre>public&nbsp;scala.collection.immutable.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;getAllConfs()</pre>
<div class="block">Return all the configuration properties that have been set (i.e. not the default).
 This creates a new copy of the config properties in the form of a Map.
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.0.0</dd></dl>
</li>
</ul>
<a name="listenerManager()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>listenerManager</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/util/ExecutionListenerManager.html" title="class in org.apache.spark.sql.util">ExecutionListenerManager</a>&nbsp;listenerManager()</pre>
</li>
</ul>
<a name="catalog()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>catalog</h4>
<pre>protected&nbsp;org.apache.spark.sql.catalyst.analysis.Catalog&nbsp;catalog()</pre>
</li>
</ul>
<a name="functionRegistry()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>functionRegistry</h4>
<pre>protected&nbsp;org.apache.spark.sql.catalyst.analysis.FunctionRegistry&nbsp;functionRegistry()</pre>
</li>
</ul>
<a name="analyzer()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>analyzer</h4>
<pre>protected&nbsp;org.apache.spark.sql.catalyst.analysis.Analyzer&nbsp;analyzer()</pre>
</li>
</ul>
<a name="optimizer()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>optimizer</h4>
<pre>protected&nbsp;org.apache.spark.sql.catalyst.optimizer.Optimizer&nbsp;optimizer()</pre>
</li>
</ul>
<a name="ddlParser()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>ddlParser</h4>
<pre>protected&nbsp;org.apache.spark.sql.execution.datasources.DDLParser&nbsp;ddlParser()</pre>
</li>
</ul>
<a name="sqlParser()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sqlParser</h4>
<pre>protected&nbsp;org.apache.spark.sql.execution.SparkSQLParser&nbsp;sqlParser()</pre>
</li>
</ul>
<a name="getSQLDialect()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getSQLDialect</h4>
<pre>protected&nbsp;org.apache.spark.sql.catalyst.ParserDialect&nbsp;getSQLDialect()</pre>
</li>
</ul>
<a name="parseSql(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parseSql</h4>
<pre>protected&nbsp;org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;parseSql(java.lang.String&nbsp;sql)</pre>
</li>
</ul>
<a name="executeSql(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>executeSql</h4>
<pre>protected&nbsp;org.apache.spark.sql.execution.QueryExecution&nbsp;executeSql(java.lang.String&nbsp;sql)</pre>
</li>
</ul>
<a name="executePlan(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>executePlan</h4>
<pre>protected&nbsp;org.apache.spark.sql.execution.QueryExecution&nbsp;executePlan(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;plan)</pre>
</li>
</ul>
<a name="dialectClassName()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>dialectClassName</h4>
<pre>protected&nbsp;java.lang.String&nbsp;dialectClassName()</pre>
</li>
</ul>
<a name="addJar(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>addJar</h4>
<pre>protected&nbsp;void&nbsp;addJar(java.lang.String&nbsp;path)</pre>
<div class="block">Add a jar to SQLContext</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>path</code> - (undocumented)</dd></dl>
</li>
</ul>
<a name="experimental()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>experimental</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/ExperimentalMethods.html" title="class in org.apache.spark.sql">ExperimentalMethods</a>&nbsp;experimental()</pre>
<div class="block">:: Experimental ::
 A collection of methods that are considered experimental, but can be used to hook into
 the query planner for advanced functionality.
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="emptyDataFrame()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>emptyDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;emptyDataFrame()</pre>
<div class="block">:: Experimental ::
 Returns a <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a> with no rows or columns.
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="udf()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>udf</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</a>&nbsp;udf()</pre>
<div class="block">A collection of methods for registering user-defined functions (UDF).
 <p>
 The following example registers a Scala closure as UDF:
 <pre><code>
   sqlContext.udf.register("myUDF", (arg1: Int, arg2: String) =&gt; arg2 + arg1)
 </code></pre>
 <p>
 The following example registers a UDF in Java:
 <pre><code>
   sqlContext.udf().register("myUDF",
       new UDF2&lt;Integer, String, String&gt;() {
           &#64;Override
           public String call(Integer arg1, String arg2) {
               return arg2 + arg1;
           }
      }, DataTypes.StringType);
 </code></pre>
 <p>
 Or, to use Java 8 lambda syntax:
 <pre><code>
   sqlContext.udf().register("myUDF",
       (Integer arg1, String arg2) -&gt; arg2 + arg1,
       DataTypes.StringType);
 </code></pre>
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0
 TODO move to SQLSession?</dd></dl>
</li>
</ul>
<a name="isCached(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isCached</h4>
<pre>public&nbsp;boolean&nbsp;isCached(java.lang.String&nbsp;tableName)</pre>
<div class="block">Returns true if the table is currently cached in-memory.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>tableName</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="cacheTable(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cacheTable</h4>
<pre>public&nbsp;void&nbsp;cacheTable(java.lang.String&nbsp;tableName)</pre>
<div class="block">Caches the specified table in-memory.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>tableName</code> - (undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="uncacheTable(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>uncacheTable</h4>
<pre>public&nbsp;void&nbsp;uncacheTable(java.lang.String&nbsp;tableName)</pre>
<div class="block">Removes the specified table from the in-memory cache.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>tableName</code> - (undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="clearCache()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>clearCache</h4>
<pre>public&nbsp;void&nbsp;clearCache()</pre>
<div class="block">Removes all cached tables from the in-memory cache.</div>
<dl><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="implicits()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>implicits</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql">SQLContext.implicits$</a>&nbsp;implicits()</pre>
<div class="block">Accessor for nested Scala object</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="createDataFrame(org.apache.spark.rdd.RDD, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;&lt;A extends scala.Product&gt;&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;createDataFrame(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;A&gt;&nbsp;rdd,
                                                  scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$1)</pre>
</li>
</ul>
<a name="createDataFrame(scala.collection.Seq, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;&lt;A extends scala.Product&gt;&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;createDataFrame(scala.collection.Seq&lt;A&gt;&nbsp;data,
                                                  scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$2)</pre>
</li>
</ul>
<a name="baseRelationToDataFrame(org.apache.spark.sql.sources.BaseRelation)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>baseRelationToDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;baseRelationToDataFrame(<a href="../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</a>&nbsp;baseRelation)</pre>
</li>
</ul>
<a name="createDataFrame(org.apache.spark.rdd.RDD, org.apache.spark.sql.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;createDataFrame(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rowRDD,
                        <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</pre>
</li>
</ul>
<a name="createDataset(scala.collection.Seq, org.apache.spark.sql.Encoder)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataset</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;&nbsp;createDataset(scala.collection.Seq&lt;T&gt;&nbsp;data,
                           <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$3)</pre>
</li>
</ul>
<a name="createDataset(org.apache.spark.rdd.RDD, org.apache.spark.sql.Encoder)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataset</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;&nbsp;createDataset(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;data,
                           <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$4)</pre>
</li>
</ul>
<a name="createDataset(java.util.List, org.apache.spark.sql.Encoder)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataset</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;&nbsp;createDataset(java.util.List&lt;T&gt;&nbsp;data,
                           <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$5)</pre>
</li>
</ul>
<a name="createDataFrame(org.apache.spark.api.java.JavaRDD, org.apache.spark.sql.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;createDataFrame(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rowRDD,
                        <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</pre>
</li>
</ul>
<a name="createDataFrame(java.util.List, org.apache.spark.sql.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;createDataFrame(java.util.List&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rows,
                        <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</pre>
</li>
</ul>
<a name="createDataFrame(org.apache.spark.rdd.RDD, java.lang.Class)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;createDataFrame(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;?&gt;&nbsp;rdd,
                        java.lang.Class&lt;?&gt;&nbsp;beanClass)</pre>
</li>
</ul>
<a name="createDataFrame(org.apache.spark.api.java.JavaRDD, java.lang.Class)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;createDataFrame(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;?&gt;&nbsp;rdd,
                        java.lang.Class&lt;?&gt;&nbsp;beanClass)</pre>
</li>
</ul>
<a name="createDataFrame(java.util.List, java.lang.Class)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;createDataFrame(java.util.List&lt;?&gt;&nbsp;data,
                        java.lang.Class&lt;?&gt;&nbsp;beanClass)</pre>
</li>
</ul>
<a name="read()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>read</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a>&nbsp;read()</pre>
</li>
</ul>
<a name="createExternalTable(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createExternalTable</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;createExternalTable(java.lang.String&nbsp;tableName,
                            java.lang.String&nbsp;path)</pre>
</li>
</ul>
<a name="createExternalTable(java.lang.String, java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createExternalTable</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;createExternalTable(java.lang.String&nbsp;tableName,
                            java.lang.String&nbsp;path,
                            java.lang.String&nbsp;source)</pre>
</li>
</ul>
<a name="createExternalTable(java.lang.String, java.lang.String, java.util.Map)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createExternalTable</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;createExternalTable(java.lang.String&nbsp;tableName,
                            java.lang.String&nbsp;source,
                            java.util.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</pre>
</li>
</ul>
<a name="createExternalTable(java.lang.String, java.lang.String, scala.collection.immutable.Map)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createExternalTable</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;createExternalTable(java.lang.String&nbsp;tableName,
                            java.lang.String&nbsp;source,
                            scala.collection.immutable.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</pre>
</li>
</ul>
<a name="createExternalTable(java.lang.String, java.lang.String, org.apache.spark.sql.types.StructType, java.util.Map)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createExternalTable</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;createExternalTable(java.lang.String&nbsp;tableName,
                            java.lang.String&nbsp;source,
                            <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema,
                            java.util.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</pre>
</li>
</ul>
<a name="createExternalTable(java.lang.String, java.lang.String, org.apache.spark.sql.types.StructType, scala.collection.immutable.Map)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createExternalTable</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;createExternalTable(java.lang.String&nbsp;tableName,
                            java.lang.String&nbsp;source,
                            <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema,
                            scala.collection.immutable.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</pre>
</li>
</ul>
<a name="dropTempTable(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>dropTempTable</h4>
<pre>public&nbsp;void&nbsp;dropTempTable(java.lang.String&nbsp;tableName)</pre>
</li>
</ul>
<a name="range(long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>range</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;range(long&nbsp;end)</pre>
</li>
</ul>
<a name="range(long, long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>range</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;range(long&nbsp;start,
              long&nbsp;end)</pre>
</li>
</ul>
<a name="range(long, long, long, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>range</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;range(long&nbsp;start,
              long&nbsp;end,
              long&nbsp;step,
              int&nbsp;numPartitions)</pre>
</li>
</ul>
<a name="sql(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sql</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;sql(java.lang.String&nbsp;sqlText)</pre>
</li>
</ul>
<a name="table(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>table</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;table(java.lang.String&nbsp;tableName)</pre>
</li>
</ul>
<a name="tables()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>tables</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;tables()</pre>
</li>
</ul>
<a name="tables(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>tables</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;tables(java.lang.String&nbsp;databaseName)</pre>
</li>
</ul>
<a name="tableNames()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>tableNames</h4>
<pre>public&nbsp;java.lang.String[]&nbsp;tableNames()</pre>
</li>
</ul>
<a name="tableNames(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>tableNames</h4>
<pre>public&nbsp;java.lang.String[]&nbsp;tableNames(java.lang.String&nbsp;databaseName)</pre>
</li>
</ul>
<a name="planner()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>planner</h4>
<pre>protected&nbsp;org.apache.spark.sql.execution.SparkPlanner&nbsp;planner()</pre>
</li>
</ul>
<a name="emptyResult()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>emptyResult</h4>
<pre>protected&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.InternalRow&gt;&nbsp;emptyResult()</pre>
</li>
</ul>
<a name="prepareForExecution()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>prepareForExecution</h4>
<pre>protected&nbsp;org.apache.spark.sql.catalyst.rules.RuleExecutor&lt;org.apache.spark.sql.execution.SparkPlan&gt;&nbsp;prepareForExecution()</pre>
</li>
</ul>
<a name="parseDataType(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parseDataType</h4>
<pre>protected&nbsp;<a href="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</a>&nbsp;parseDataType(java.lang.String&nbsp;dataTypeString)</pre>
</li>
</ul>
<a name="applySchemaToPythonRDD(org.apache.spark.rdd.RDD, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>applySchemaToPythonRDD</h4>
<pre>protected&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;applySchemaToPythonRDD(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.Object[]&gt;&nbsp;rdd,
                               java.lang.String&nbsp;schemaString)</pre>
</li>
</ul>
<a name="applySchemaToPythonRDD(org.apache.spark.rdd.RDD, org.apache.spark.sql.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>applySchemaToPythonRDD</h4>
<pre>protected&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;applySchemaToPythonRDD(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.Object[]&gt;&nbsp;rdd,
                               <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</pre>
</li>
</ul>
<a name="getSchema(java.lang.Class)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getSchema</h4>
<pre>protected&nbsp;scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.AttributeReference&gt;&nbsp;getSchema(java.lang.Class&lt;?&gt;&nbsp;beanClass)</pre>
</li>
</ul>
<a name="applySchema(org.apache.spark.rdd.RDD, org.apache.spark.sql.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>applySchema</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;applySchema(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rowRDD,
                    <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</pre>
</li>
</ul>
<a name="applySchema(org.apache.spark.api.java.JavaRDD, org.apache.spark.sql.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>applySchema</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;applySchema(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rowRDD,
                    <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</pre>
</li>
</ul>
<a name="applySchema(org.apache.spark.rdd.RDD, java.lang.Class)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>applySchema</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;applySchema(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;?&gt;&nbsp;rdd,
                    java.lang.Class&lt;?&gt;&nbsp;beanClass)</pre>
</li>
</ul>
<a name="applySchema(org.apache.spark.api.java.JavaRDD, java.lang.Class)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>applySchema</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;applySchema(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;?&gt;&nbsp;rdd,
                    java.lang.Class&lt;?&gt;&nbsp;beanClass)</pre>
</li>
</ul>
<a name="parquetFile(scala.collection.Seq)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parquetFile</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;parquetFile(scala.collection.Seq&lt;java.lang.String&gt;&nbsp;paths)</pre>
</li>
</ul>
<a name="jsonFile(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jsonFile</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;jsonFile(java.lang.String&nbsp;path)</pre>
<div class="block"><span class="strong">Deprecated.</span>&nbsp;<i>As of 1.4.0, replaced by <code>read().json()</code>. This will be removed in Spark 2.0.</i></div>
<div class="block">Loads a JSON file (one object per line), returning the result as a <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a>.
 It goes through the entire dataset once to determine the schema.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>path</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="jsonFile(java.lang.String, org.apache.spark.sql.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jsonFile</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;jsonFile(java.lang.String&nbsp;path,
                 <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</pre>
<div class="block"><span class="strong">Deprecated.</span>&nbsp;<i>As of 1.4.0, replaced by <code>read().json()</code>. This will be removed in Spark 2.0.</i></div>
<div class="block">Loads a JSON file (one object per line) and applies the given schema,
 returning the result as a <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a>.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>path</code> - (undocumented)</dd><dd><code>schema</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="jsonFile(java.lang.String, double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jsonFile</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;jsonFile(java.lang.String&nbsp;path,
                 double&nbsp;samplingRatio)</pre>
<div class="block"><span class="strong">Deprecated.</span>&nbsp;<i>As of 1.4.0, replaced by <code>read().json()</code>. This will be removed in Spark 2.0.</i></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>path</code> - (undocumented)</dd><dd><code>samplingRatio</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="jsonRDD(org.apache.spark.rdd.RDD)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jsonRDD</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;jsonRDD(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.String&gt;&nbsp;json)</pre>
<div class="block"><span class="strong">Deprecated.</span>&nbsp;<i>As of 1.4.0, replaced by <code>read().json()</code>. This will be removed in Spark 2.0.</i></div>
<div class="block">Loads an RDD[String] storing JSON objects (one object per record), returning the result as a
 <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a>.
 It goes through the entire dataset once to determine the schema.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>json</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="jsonRDD(org.apache.spark.api.java.JavaRDD)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jsonRDD</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;jsonRDD(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;java.lang.String&gt;&nbsp;json)</pre>
<div class="block"><span class="strong">Deprecated.</span>&nbsp;<i>As of 1.4.0, replaced by <code>read().json()</code>. This will be removed in Spark 2.0.</i></div>
<div class="block">Loads an RDD[String] storing JSON objects (one object per record), returning the result as a
 <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a>.
 It goes through the entire dataset once to determine the schema.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>json</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="jsonRDD(org.apache.spark.rdd.RDD, org.apache.spark.sql.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jsonRDD</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;jsonRDD(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.String&gt;&nbsp;json,
                <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</pre>
<div class="block"><span class="strong">Deprecated.</span>&nbsp;<i>As of 1.4.0, replaced by <code>read().json()</code>. This will be removed in Spark 2.0.</i></div>
<div class="block">Loads an RDD[String] storing JSON objects (one object per record) and applies the given schema,
 returning the result as a <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a>.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>json</code> - (undocumented)</dd><dd><code>schema</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="jsonRDD(org.apache.spark.api.java.JavaRDD, org.apache.spark.sql.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jsonRDD</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;jsonRDD(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;java.lang.String&gt;&nbsp;json,
                <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</pre>
<div class="block"><span class="strong">Deprecated.</span>&nbsp;<i>As of 1.4.0, replaced by <code>read().json()</code>. This will be removed in Spark 2.0.</i></div>
<div class="block">Loads an JavaRDD<String> storing JSON objects (one object per record) and applies the given
 schema, returning the result as a <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a>.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>json</code> - (undocumented)</dd><dd><code>schema</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="jsonRDD(org.apache.spark.rdd.RDD, double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jsonRDD</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;jsonRDD(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.String&gt;&nbsp;json,
                double&nbsp;samplingRatio)</pre>
<div class="block"><span class="strong">Deprecated.</span>&nbsp;<i>As of 1.4.0, replaced by <code>read().json()</code>. This will be removed in Spark 2.0.</i></div>
<div class="block">Loads an RDD[String] storing JSON objects (one object per record) inferring the
 schema, returning the result as a <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a>.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>json</code> - (undocumented)</dd><dd><code>samplingRatio</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="jsonRDD(org.apache.spark.api.java.JavaRDD, double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jsonRDD</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;jsonRDD(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;java.lang.String&gt;&nbsp;json,
                double&nbsp;samplingRatio)</pre>
<div class="block"><span class="strong">Deprecated.</span>&nbsp;<i>As of 1.4.0, replaced by <code>read().json()</code>. This will be removed in Spark 2.0.</i></div>
<div class="block">Loads a JavaRDD[String] storing JSON objects (one object per record) inferring the
 schema, returning the result as a <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a>.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>json</code> - (undocumented)</dd><dd><code>samplingRatio</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="load(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>load</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;load(java.lang.String&nbsp;path)</pre>
<div class="block"><span class="strong">Deprecated.</span>&nbsp;<i>As of 1.4.0, replaced by <code>read().load(path)</code>. This will be removed in Spark 2.0.</i></div>
<div class="block">Returns the dataset stored at path as a DataFrame,
 using the default data source configured by spark.sql.sources.default.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>path</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="load(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>load</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;load(java.lang.String&nbsp;path,
             java.lang.String&nbsp;source)</pre>
<div class="block"><span class="strong">Deprecated.</span>&nbsp;<i>As of 1.4.0, replaced by <code>read().format(source).load(path)</code>.
             This will be removed in Spark 2.0.</i></div>
<div class="block">Returns the dataset stored at path as a DataFrame, using the given data source.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>path</code> - (undocumented)</dd><dd><code>source</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="load(java.lang.String, java.util.Map)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>load</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;load(java.lang.String&nbsp;source,
             java.util.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</pre>
<div class="block"><span class="strong">Deprecated.</span>&nbsp;<i>As of 1.4.0, replaced by <code>read().format(source).options(options).load()</code>.
             This will be removed in Spark 2.0.</i></div>
<div class="block">(Java-specific) Returns the dataset specified by the given data source and
 a set of options as a DataFrame.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>source</code> - (undocumented)</dd><dd><code>options</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="load(java.lang.String, scala.collection.immutable.Map)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>load</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;load(java.lang.String&nbsp;source,
             scala.collection.immutable.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</pre>
<div class="block"><span class="strong">Deprecated.</span>&nbsp;<i>As of 1.4.0, replaced by <code>read().format(source).options(options).load()</code>.</i></div>
<div class="block">(Scala-specific) Returns the dataset specified by the given data source and
 a set of options as a DataFrame.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>source</code> - (undocumented)</dd><dd><code>options</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="load(java.lang.String, org.apache.spark.sql.types.StructType, java.util.Map)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>load</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;load(java.lang.String&nbsp;source,
             <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema,
             java.util.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</pre>
<div class="block"><span class="strong">Deprecated.</span>&nbsp;<i>As of 1.4.0, replaced by
            <code>read().format(source).schema(schema).options(options).load()</code>.</i></div>
<div class="block">(Java-specific) Returns the dataset specified by the given data source and
 a set of options as a DataFrame, using the given schema as the schema of the DataFrame.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>source</code> - (undocumented)</dd><dd><code>schema</code> - (undocumented)</dd><dd><code>options</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="load(java.lang.String, org.apache.spark.sql.types.StructType, scala.collection.immutable.Map)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>load</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;load(java.lang.String&nbsp;source,
             <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema,
             scala.collection.immutable.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</pre>
<div class="block"><span class="strong">Deprecated.</span>&nbsp;<i>As of 1.4.0, replaced by
            <code>read().format(source).schema(schema).options(options).load()</code>.</i></div>
<div class="block">(Scala-specific) Returns the dataset specified by the given data source and
 a set of options as a DataFrame, using the given schema as the schema of the DataFrame.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>source</code> - (undocumented)</dd><dd><code>schema</code> - (undocumented)</dd><dd><code>options</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="jdbc(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jdbc</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;jdbc(java.lang.String&nbsp;url,
             java.lang.String&nbsp;table)</pre>
<div class="block"><span class="strong">Deprecated.</span>&nbsp;<i>As of 1.4.0, replaced by <code>read().jdbc()</code>. This will be removed in Spark 2.0.</i></div>
<div class="block">Construct a <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a> representing the database table accessible via JDBC URL
 url named table.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>url</code> - (undocumented)</dd><dd><code>table</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="jdbc(java.lang.String, java.lang.String, java.lang.String, long, long, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jdbc</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;jdbc(java.lang.String&nbsp;url,
             java.lang.String&nbsp;table,
             java.lang.String&nbsp;columnName,
             long&nbsp;lowerBound,
             long&nbsp;upperBound,
             int&nbsp;numPartitions)</pre>
<div class="block"><span class="strong">Deprecated.</span>&nbsp;<i>As of 1.4.0, replaced by <code>read().jdbc()</code>. This will be removed in Spark 2.0.</i></div>
<div class="block">Construct a <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a> representing the database table accessible via JDBC URL
 url named table.  Partitions of the table will be retrieved in parallel based on the parameters
 passed to this function.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>columnName</code> - the name of a column of integral type that will be used for partitioning.</dd><dd><code>lowerBound</code> - the minimum value of <code>columnName</code> used to decide partition stride</dd><dd><code>upperBound</code> - the maximum value of <code>columnName</code> used to decide partition stride</dd><dd><code>numPartitions</code> - the number of partitions.  the range <code>minValue</code>-<code>maxValue</code> will be split
                      evenly into this many partitions</dd><dd><code>url</code> - (undocumented)</dd><dd><code>table</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="jdbc(java.lang.String, java.lang.String, java.lang.String[])">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>jdbc</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;jdbc(java.lang.String&nbsp;url,
             java.lang.String&nbsp;table,
             java.lang.String[]&nbsp;theParts)</pre>
<div class="block"><span class="strong">Deprecated.</span>&nbsp;<i>As of 1.4.0, replaced by <code>read().jdbc()</code>. This will be removed in Spark 2.0.</i></div>
<div class="block">Construct a <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a> representing the database table accessible via JDBC URL
 url named table. The theParts parameter gives a list expressions
 suitable for inclusion in WHERE clauses; each one defines one partition
 of the <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a>.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>url</code> - (undocumented)</dd><dd><code>table</code> - (undocumented)</dd><dd><code>theParts</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/SaveMode.html" title="enum in org.apache.spark.sql"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/SQLContext.html" target="_top">Frames</a></li>
<li><a href="SQLContext.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../lib/api-javadocs.js"></script></body>
</html>
