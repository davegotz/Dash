<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_79) on Fri Feb 26 20:48:39 PST 2016 -->
<title>Dataset</title>
<meta name="date" content="2016-02-26">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="Dataset";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/DataFrameWriter.html" title="class in org.apache.spark.sql"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/apache/spark/sql/DatasetHolder.html" title="class in org.apache.spark.sql"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/Dataset.html" target="_top">Frames</a></li>
<li><a href="Dataset.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql</div>
<h2 title="Class Dataset" class="title">Class Dataset&lt;T&gt;</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.sql.Dataset&lt;T&gt;</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable, <a href="../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a>, org.apache.spark.sql.execution.Queryable</dd>
</dl>
<hr>
<br>
<pre>public class <span class="strong">Dataset&lt;T&gt;</span>
extends java.lang.Object
implements org.apache.spark.sql.execution.Queryable, scala.Serializable, <a href="../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></pre>
<div class="block">:: Experimental ::
 A <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> is a strongly typed collection of objects that can be transformed in parallel
 using functional or relational operations.
 <p>
 A <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> differs from an <code>RDD</code> in the following ways:
  - Internally, a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> is represented by a Catalyst logical plan and the data is stored
    in the encoded form.  This representation allows for additional logical operations and
    enables many operations (sorting, shuffling, etc.) to be performed without deserializing to
    an object.
  - The creation of a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> requires the presence of an explicit <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql"><code>Encoder</code></a> that can be
    used to serialize the object into a binary format.  Encoders are also capable of mapping the
    schema of a given object to the Spark SQL type system.  In contrast, RDDs rely on runtime
    reflection based serialization. Operations that change the type of object stored in the
    dataset also need an encoder for the new type.
 <p>
 A <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> can be thought of as a specialized DataFrame, where the elements map to a specific
 JVM object type, instead of to a generic <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a> container. A DataFrame can be transformed into
 specific Dataset by calling <code>df.as[ElementType]</code>.  Similarly you can transform a strongly-typed
 <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> to a generic DataFrame by calling <code>ds.toDF()</code>.
 <p>
 COMPATIBILITY NOTE: Long term we plan to make <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a> extend <code>Dataset[Row]</code>.  However,
 making this change to the class hierarchy would break the function signatures for the existing
 functional operations (map, flatMap, etc).  As such, this class should be considered a preview
 of the final API.  Changes will be made to the interface after Spark 1.6.
 <p></div>
<dl><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd>
<dt><span class="strong">See Also:</span></dt><dd><a href="../../../../serialized-form.html#org.apache.spark.sql.Dataset">Serialized Form</a></dd></dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#as(org.apache.spark.sql.Encoder)">as</a></strong>(<a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;evidence$1)</code>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> where each record has been mapped on to the specified type.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#as(java.lang.String)">as</a></strong>(java.lang.String&nbsp;alias)</code>
<div class="block">Applies a logical alias to this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that can be used to disambiguate columns that have
 the same name after two Datasets have been joined.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.spark.sql.catalyst.encoders.ExpressionEncoder&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#boundTEncoder()">boundTEncoder</a></strong>()</code>
<div class="block">The encoder where the expressions used to construct an object from an input row have been
 bound to the ordinals of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>'s output schema.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#cache()">cache</a></strong>()</code>
<div class="block">Persist this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with the default storage level (<code>MEMORY_AND_DISK</code>).</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#coalesce(int)">coalesce</a></strong>(int&nbsp;numPartitions)</code>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that has exactly <code>numPartitions</code> partitions.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.lang.Object</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#collect()">collect</a></strong>()</code>
<div class="block">Returns an array that contains all the elements in this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.util.List&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#collectAsList()">collectAsList</a></strong>()</code>
<div class="block">Returns an array that contains all the elements in this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>long</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#count()">count</a></strong>()</code>
<div class="block">Returns the number of elements in the <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#distinct()">distinct</a></strong>()</code>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that contains only the unique elements of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#explain()">explain</a></strong>()</code>
<div class="block">Prints the physical plan to the console for debugging purposes.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#explain(boolean)">explain</a></strong>(boolean&nbsp;extended)</code>
<div class="block">Prints the plans (logical and physical) to the console for debugging purposes.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#filter(org.apache.spark.api.java.function.FilterFunction)">filter</a></strong>(<a href="../../../../org/apache/spark/api/java/function/FilterFunction.html" title="interface in org.apache.spark.api.java.function">FilterFunction</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;func)</code>
<div class="block">(Java-specific)
 Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that only contains elements where <code>func</code> returns <code>true</code>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#filter(scala.Function1)">filter</a></strong>(scala.Function1&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,java.lang.Object&gt;&nbsp;func)</code>
<div class="block">(Scala-specific)
 Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that only contains elements where <code>func</code> returns <code>true</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#first()">first</a></strong>()</code>
<div class="block">Returns the first element in this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#flatMap(org.apache.spark.api.java.function.FlatMapFunction,%20org.apache.spark.sql.Encoder)">flatMap</a></strong>(<a href="../../../../org/apache/spark/api/java/function/FlatMapFunction.html" title="interface in org.apache.spark.api.java.function">FlatMapFunction</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U&gt;&nbsp;f,
       <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;encoder)</code>
<div class="block">(Java-specific)
 Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by first applying a function to all elements of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>,
 and then flattening the results.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#flatMap(scala.Function1,%20org.apache.spark.sql.Encoder)">flatMap</a></strong>(scala.Function1&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,scala.collection.TraversableOnce&lt;U&gt;&gt;&nbsp;func,
       <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;evidence$4)</code>
<div class="block">(Scala-specific)
 Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by first applying a function to all elements of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>,
 and then flattening the results.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#foreach(org.apache.spark.api.java.function.ForeachFunction)">foreach</a></strong>(<a href="../../../../org/apache/spark/api/java/function/ForeachFunction.html" title="interface in org.apache.spark.api.java.function">ForeachFunction</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;func)</code>
<div class="block">(Java-specific)
 Runs <code>func</code> on each element of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#foreach(scala.Function1)">foreach</a></strong>(scala.Function1&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,scala.runtime.BoxedUnit&gt;&nbsp;func)</code>
<div class="block">(Scala-specific)
 Runs <code>func</code> on each element of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#foreachPartition(org.apache.spark.api.java.function.ForeachPartitionFunction)">foreachPartition</a></strong>(<a href="../../../../org/apache/spark/api/java/function/ForeachPartitionFunction.html" title="interface in org.apache.spark.api.java.function">ForeachPartitionFunction</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;func)</code>
<div class="block">(Java-specific)
 Runs <code>func</code> on each partition of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#foreachPartition(scala.Function1)">foreachPartition</a></strong>(scala.Function1&lt;scala.collection.Iterator&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;,scala.runtime.BoxedUnit&gt;&nbsp;func)</code>
<div class="block">(Scala-specific)
 Runs <code>func</code> on each partition of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/GroupedDataset.html" title="class in org.apache.spark.sql">GroupedDataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>,<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#groupBy(org.apache.spark.sql.Column...)">groupBy</a></strong>(<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;cols)</code>
<div class="block">Returns a <a href="../../../../org/apache/spark/sql/GroupedDataset.html" title="class in org.apache.spark.sql"><code>GroupedDataset</code></a> where the data is grouped by the given <a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expressions.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;K&gt;&nbsp;<a href="../../../../org/apache/spark/sql/GroupedDataset.html" title="class in org.apache.spark.sql">GroupedDataset</a>&lt;K,<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#groupBy(scala.Function1,%20org.apache.spark.sql.Encoder)">groupBy</a></strong>(scala.Function1&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,K&gt;&nbsp;func,
       <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;K&gt;&nbsp;evidence$5)</code>
<div class="block">(Scala-specific)
 Returns a <a href="../../../../org/apache/spark/sql/GroupedDataset.html" title="class in org.apache.spark.sql"><code>GroupedDataset</code></a> where the data is grouped by the given key <code>func</code>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;K&gt;&nbsp;<a href="../../../../org/apache/spark/sql/GroupedDataset.html" title="class in org.apache.spark.sql">GroupedDataset</a>&lt;K,<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#groupBy(org.apache.spark.api.java.function.MapFunction,%20org.apache.spark.sql.Encoder)">groupBy</a></strong>(<a href="../../../../org/apache/spark/api/java/function/MapFunction.html" title="interface in org.apache.spark.api.java.function">MapFunction</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,K&gt;&nbsp;func,
       <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;K&gt;&nbsp;encoder)</code>
<div class="block">(Java-specific)
 Returns a <a href="../../../../org/apache/spark/sql/GroupedDataset.html" title="class in org.apache.spark.sql"><code>GroupedDataset</code></a> where the data is grouped by the given key <code>func</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/GroupedDataset.html" title="class in org.apache.spark.sql">GroupedDataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>,<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#groupBy(scala.collection.Seq)">groupBy</a></strong>(scala.collection.Seq&lt;<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;cols)</code>
<div class="block">Returns a <a href="../../../../org/apache/spark/sql/GroupedDataset.html" title="class in org.apache.spark.sql"><code>GroupedDataset</code></a> where the data is grouped by the given <a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expressions.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#intersect(org.apache.spark.sql.Dataset)">intersect</a></strong>(<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other)</code>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that contains only the elements of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that are also
 present in <code>other</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#joinWith(org.apache.spark.sql.Dataset,%20org.apache.spark.sql.Column)">joinWith</a></strong>(<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;&nbsp;other,
        <a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;condition)</code>
<div class="block">Using inner equi-join to join this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> returning a <code>Tuple2</code> for each pair
 where <code>condition</code> evaluates to true.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#joinWith(org.apache.spark.sql.Dataset,%20org.apache.spark.sql.Column,%20java.lang.String)">joinWith</a></strong>(<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;&nbsp;other,
        <a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;condition,
        java.lang.String&nbsp;joinType)</code>
<div class="block">Joins this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> returning a <code>Tuple2</code> for each pair where <code>condition</code> evaluates to
 true.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#map(scala.Function1,%20org.apache.spark.sql.Encoder)">map</a></strong>(scala.Function1&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U&gt;&nbsp;func,
   <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;evidence$2)</code>
<div class="block">(Scala-specific)
 Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that contains the result of applying <code>func</code> to each element.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#map(org.apache.spark.api.java.function.MapFunction,%20org.apache.spark.sql.Encoder)">map</a></strong>(<a href="../../../../org/apache/spark/api/java/function/MapFunction.html" title="interface in org.apache.spark.api.java.function">MapFunction</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U&gt;&nbsp;func,
   <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;encoder)</code>
<div class="block">(Java-specific)
 Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that contains the result of applying <code>func</code> to each element.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#mapPartitions(scala.Function1,%20org.apache.spark.sql.Encoder)">mapPartitions</a></strong>(scala.Function1&lt;scala.collection.Iterator&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;,scala.collection.Iterator&lt;U&gt;&gt;&nbsp;func,
             <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;evidence$3)</code>
<div class="block">(Scala-specific)
 Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that contains the result of applying <code>func</code> to each partition.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#mapPartitions(org.apache.spark.api.java.function.MapPartitionsFunction,%20org.apache.spark.sql.Encoder)">mapPartitions</a></strong>(<a href="../../../../org/apache/spark/api/java/function/MapPartitionsFunction.html" title="interface in org.apache.spark.api.java.function">MapPartitionsFunction</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U&gt;&nbsp;f,
             <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;encoder)</code>
<div class="block">(Java-specific)
 Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that contains the result of applying <code>func</code> to each partition.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#persist()">persist</a></strong>()</code>
<div class="block">Persist this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with the default storage level (<code>MEMORY_AND_DISK</code>).</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#persist(org.apache.spark.storage.StorageLevel)">persist</a></strong>(<a href="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a>&nbsp;newLevel)</code>
<div class="block">Persist this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with the given storage level.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#printSchema()">printSchema</a></strong>()</code>
<div class="block">Prints the schema of the underlying <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> to the console in a nice tree format.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.spark.sql.execution.QueryExecution</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#queryExecution()">queryExecution</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#rdd()">rdd</a></strong>()</code>
<div class="block">Converts this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> to an <code>RDD</code>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#reduce(scala.Function2)">reduce</a></strong>(scala.Function2&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;func)</code>
<div class="block">(Scala-specific)
 Reduces the elements of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> using the specified binary function.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#reduce(org.apache.spark.api.java.function.ReduceFunction)">reduce</a></strong>(<a href="../../../../org/apache/spark/api/java/function/ReduceFunction.html" title="interface in org.apache.spark.api.java.function">ReduceFunction</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;func)</code>
<div class="block">(Java-specific)
 Reduces the elements of this Dataset using the specified binary function.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#repartition(int)">repartition</a></strong>(int&nbsp;numPartitions)</code>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that has exactly <code>numPartitions</code> partitions.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.spark.sql.catalyst.encoders.ExpressionEncoder&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#resolvedTEncoder()">resolvedTEncoder</a></strong>()</code>
<div class="block">The encoder for this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that has been resolved to its output schema.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#sample(boolean,%20double)">sample</a></strong>(boolean&nbsp;withReplacement,
      double&nbsp;fraction)</code>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by sampling a fraction of records, using a random seed.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#sample(boolean,%20double,%20long)">sample</a></strong>(boolean&nbsp;withReplacement,
      double&nbsp;fraction,
      long&nbsp;seed)</code>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by sampling a fraction of records.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#schema()">schema</a></strong>()</code>
<div class="block">Returns the schema of the encoded form of the objects in this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#select(org.apache.spark.sql.Column...)">select</a></strong>(<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;cols)</code>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a> by selecting a set of column based expressions.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#select(scala.collection.Seq)">select</a></strong>(scala.collection.Seq&lt;<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;cols)</code>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a> by selecting a set of column based expressions.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;U1&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U1&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#select(org.apache.spark.sql.TypedColumn,%20org.apache.spark.sql.Encoder)">select</a></strong>(<a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U1&gt;&nbsp;c1,
      <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U1&gt;&nbsp;evidence$6)</code>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by computing the given <a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expression for each element.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;U1,U2&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple2&lt;U1,U2&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#select(org.apache.spark.sql.TypedColumn,%20org.apache.spark.sql.TypedColumn)">select</a></strong>(<a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U1&gt;&nbsp;c1,
      <a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U2&gt;&nbsp;c2)</code>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by computing the given <a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expressions for each element.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;U1,U2,U3&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple3&lt;U1,U2,U3&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#select(org.apache.spark.sql.TypedColumn,%20org.apache.spark.sql.TypedColumn,%20org.apache.spark.sql.TypedColumn)">select</a></strong>(<a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U1&gt;&nbsp;c1,
      <a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U2&gt;&nbsp;c2,
      <a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U3&gt;&nbsp;c3)</code>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by computing the given <a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expressions for each element.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;U1,U2,U3,U4&gt;&nbsp;<br><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple4&lt;U1,U2,U3,U4&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#select(org.apache.spark.sql.TypedColumn,%20org.apache.spark.sql.TypedColumn,%20org.apache.spark.sql.TypedColumn,%20org.apache.spark.sql.TypedColumn)">select</a></strong>(<a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U1&gt;&nbsp;c1,
      <a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U2&gt;&nbsp;c2,
      <a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U3&gt;&nbsp;c3,
      <a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U4&gt;&nbsp;c4)</code>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by computing the given <a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expressions for each element.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;U1,U2,U3,U4,U5&gt;&nbsp;<br><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple5&lt;U1,U2,U3,U4,U5&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#select(org.apache.spark.sql.TypedColumn,%20org.apache.spark.sql.TypedColumn,%20org.apache.spark.sql.TypedColumn,%20org.apache.spark.sql.TypedColumn,%20org.apache.spark.sql.TypedColumn)">select</a></strong>(<a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U1&gt;&nbsp;c1,
      <a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U2&gt;&nbsp;c2,
      <a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U3&gt;&nbsp;c3,
      <a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U4&gt;&nbsp;c4,
      <a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U5&gt;&nbsp;c5)</code>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by computing the given <a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expressions for each element.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;?&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#selectUntyped(scala.collection.Seq)">selectUntyped</a></strong>(scala.collection.Seq&lt;<a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;?,?&gt;&gt;&nbsp;columns)</code>
<div class="block">Internal helper function for building typed selects that return tuples.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#show()">show</a></strong>()</code>
<div class="block">Displays the top 20 rows of <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> in a tabular form.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#show(boolean)">show</a></strong>(boolean&nbsp;truncate)</code>
<div class="block">Displays the top 20 rows of <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> in a tabular form.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#show(int)">show</a></strong>(int&nbsp;numRows)</code>
<div class="block">Displays the content of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> in a tabular form.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#show(int,%20boolean)">show</a></strong>(int&nbsp;numRows,
    boolean&nbsp;truncate)</code>
<div class="block">Displays the <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> in a tabular form.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#sqlContext()">sqlContext</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#subtract(org.apache.spark.sql.Dataset)">subtract</a></strong>(<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other)</code>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> where any elements present in <code>other</code> have been removed.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.lang.Object</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#take(int)">take</a></strong>(int&nbsp;num)</code>
<div class="block">Returns the first <code>num</code> elements of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> as an array.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.util.List&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#takeAsList(int)">takeAsList</a></strong>(int&nbsp;num)</code>
<div class="block">Returns the first <code>num</code> elements of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> as an array.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#toDF()">toDF</a></strong>()</code>
<div class="block">Converts this strongly typed collection of data to generic Dataframe.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#toDS()">toDS</a></strong>()</code>
<div class="block">Returns this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#transform(scala.Function1)">transform</a></strong>(scala.Function1&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;,<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;&gt;&nbsp;t)</code>
<div class="block">Concise syntax for chaining custom transformations.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#union(org.apache.spark.sql.Dataset)">union</a></strong>(<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other)</code>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that contains the elements of both this and the <code>other</code> <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>
 combined.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#unpersist()">unpersist</a></strong>()</code>
<div class="block">Mark the <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> as non-persistent, and remove all blocks for it from memory and disk.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#unpersist(boolean)">unpersist</a></strong>(boolean&nbsp;blocking)</code>
<div class="block">Mark the <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> as non-persistent, and remove all blocks for it from memory and disk.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.spark.sql.catalyst.encoders.ExpressionEncoder&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/Dataset.html#unresolvedTEncoder()">unresolvedTEncoder</a></strong>()</code>
<div class="block">An unresolved version of the internal encoder for the type of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.sql.execution.Queryable">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.sql.execution.Queryable</h3>
<code>formatString, formatString$default$4, showString$default$2, toString</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.Logging">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.<a href="../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></h3>
<code><a href="../../../../org/apache/spark/Logging.html#initializeIfNecessary()">initializeIfNecessary</a>, <a href="../../../../org/apache/spark/Logging.html#initializeLogging()">initializeLogging</a>, <a href="../../../../org/apache/spark/Logging.html#isTraceEnabled()">isTraceEnabled</a>, <a href="../../../../org/apache/spark/Logging.html#log_()">log_</a>, <a href="../../../../org/apache/spark/Logging.html#log()">log</a>, <a href="../../../../org/apache/spark/Logging.html#logDebug(scala.Function0)">logDebug</a>, <a href="../../../../org/apache/spark/Logging.html#logDebug(scala.Function0,%20java.lang.Throwable)">logDebug</a>, <a href="../../../../org/apache/spark/Logging.html#logError(scala.Function0)">logError</a>, <a href="../../../../org/apache/spark/Logging.html#logError(scala.Function0,%20java.lang.Throwable)">logError</a>, <a href="../../../../org/apache/spark/Logging.html#logInfo(scala.Function0)">logInfo</a>, <a href="../../../../org/apache/spark/Logging.html#logInfo(scala.Function0,%20java.lang.Throwable)">logInfo</a>, <a href="../../../../org/apache/spark/Logging.html#logName()">logName</a>, <a href="../../../../org/apache/spark/Logging.html#logTrace(scala.Function0)">logTrace</a>, <a href="../../../../org/apache/spark/Logging.html#logTrace(scala.Function0,%20java.lang.Throwable)">logTrace</a>, <a href="../../../../org/apache/spark/Logging.html#logWarning(scala.Function0)">logWarning</a>, <a href="../../../../org/apache/spark/Logging.html#logWarning(scala.Function0,%20java.lang.Throwable)">logWarning</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="groupBy(org.apache.spark.sql.Column...)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>groupBy</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/GroupedDataset.html" title="class in org.apache.spark.sql">GroupedDataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>,<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;groupBy(<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;cols)</pre>
<div class="block">Returns a <a href="../../../../org/apache/spark/sql/GroupedDataset.html" title="class in org.apache.spark.sql"><code>GroupedDataset</code></a> where the data is grouped by the given <a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expressions.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>cols</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="select(org.apache.spark.sql.Column...)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>select</h4>
<pre>protected&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;select(<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;cols)</pre>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a> by selecting a set of column based expressions.
 <pre><code>
   df.select($"colA", $"colB" + 1)
 </code></pre></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>cols</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="sqlContext()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sqlContext</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;sqlContext()</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>sqlContext</code>&nbsp;in interface&nbsp;<code>org.apache.spark.sql.execution.Queryable</code></dd>
</dl>
</li>
</ul>
<a name="queryExecution()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>queryExecution</h4>
<pre>public&nbsp;org.apache.spark.sql.execution.QueryExecution&nbsp;queryExecution()</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>queryExecution</code>&nbsp;in interface&nbsp;<code>org.apache.spark.sql.execution.Queryable</code></dd>
</dl>
</li>
</ul>
<a name="unresolvedTEncoder()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>unresolvedTEncoder</h4>
<pre>public&nbsp;org.apache.spark.sql.catalyst.encoders.ExpressionEncoder&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;unresolvedTEncoder()</pre>
<div class="block">An unresolved version of the internal encoder for the type of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.  This one is
 marked implicit so that we can use it when constructing new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> objects that have the
 same object type (that will be possibly resolved to a different schema).</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="resolvedTEncoder()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>resolvedTEncoder</h4>
<pre>public&nbsp;org.apache.spark.sql.catalyst.encoders.ExpressionEncoder&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;resolvedTEncoder()</pre>
<div class="block">The encoder for this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that has been resolved to its output schema.</div>
</li>
</ul>
<a name="boundTEncoder()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>boundTEncoder</h4>
<pre>public&nbsp;org.apache.spark.sql.catalyst.encoders.ExpressionEncoder&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;boundTEncoder()</pre>
<div class="block">The encoder where the expressions used to construct an object from an input row have been
 bound to the ordinals of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>'s output schema.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="schema()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>schema</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema()</pre>
<div class="block">Returns the schema of the encoded form of the objects in this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>schema</code>&nbsp;in interface&nbsp;<code>org.apache.spark.sql.execution.Queryable</code></dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="printSchema()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>printSchema</h4>
<pre>public&nbsp;void&nbsp;printSchema()</pre>
<div class="block">Prints the schema of the underlying <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> to the console in a nice tree format.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>printSchema</code>&nbsp;in interface&nbsp;<code>org.apache.spark.sql.execution.Queryable</code></dd>
<dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="explain(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>explain</h4>
<pre>public&nbsp;void&nbsp;explain(boolean&nbsp;extended)</pre>
<div class="block">Prints the plans (logical and physical) to the console for debugging purposes.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>explain</code>&nbsp;in interface&nbsp;<code>org.apache.spark.sql.execution.Queryable</code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>extended</code> - (undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="explain()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>explain</h4>
<pre>public&nbsp;void&nbsp;explain()</pre>
<div class="block">Prints the physical plan to the console for debugging purposes.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>explain</code>&nbsp;in interface&nbsp;<code>org.apache.spark.sql.execution.Queryable</code></dd>
<dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="as(org.apache.spark.sql.Encoder)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>as</h4>
<pre>public&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;&nbsp;as(<a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;evidence$1)</pre>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> where each record has been mapped on to the specified type.  The
 method used to map columns depend on the type of <code>U</code>:
  - When <code>U</code> is a class, fields for the class will be mapped to columns of the same name
    (case sensitivity is determined by <code>spark.sql.caseSensitive</code>)
  - When <code>U</code> is a tuple, the columns will be be mapped by ordinal (i.e. the first column will
    be assigned to <code>_1</code>).
  - When <code>U</code> is a primitive type (i.e. String, Int, etc). then the first column of the
    <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a> will be used.
 <p>
 If the schema of the <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a> does not match the desired <code>U</code> type, you can use <code>select</code>
 along with <code>alias</code> or <code>as</code> to rearrange or rename as required.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>evidence$1</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="as(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>as</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;as(java.lang.String&nbsp;alias)</pre>
<div class="block">Applies a logical alias to this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that can be used to disambiguate columns that have
 the same name after two Datasets have been joined.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>alias</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="toDF()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>toDF</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;toDF()</pre>
<div class="block">Converts this strongly typed collection of data to generic Dataframe.  In contrast to the
 strongly typed objects that Dataset operations work on, a Dataframe returns generic <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a>
 objects that allow fields to be accessed by ordinal or name.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="toDS()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>toDS</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;toDS()</pre>
<div class="block">Returns this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="rdd()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rdd</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;rdd()</pre>
<div class="block">Converts this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> to an <code>RDD</code>.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="count()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>count</h4>
<pre>public&nbsp;long&nbsp;count()</pre>
<div class="block">Returns the number of elements in the <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="show(int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>show</h4>
<pre>public&nbsp;void&nbsp;show(int&nbsp;numRows)</pre>
<div class="block">Displays the content of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> in a tabular form. Strings more than 20 characters
 will be truncated, and all cells will be aligned right. For example:
 <pre><code>
   year  month AVG('Adj Close) MAX('Adj Close)
   1980  12    0.503218        0.595103
   1981  01    0.523289        0.570307
   1982  02    0.436504        0.475256
   1983  03    0.410516        0.442194
   1984  04    0.450090        0.483521
 </code></pre></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>numRows</code> - Number of rows to show
 <p></dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="show()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>show</h4>
<pre>public&nbsp;void&nbsp;show()</pre>
<div class="block">Displays the top 20 rows of <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> in a tabular form. Strings more than 20 characters
 will be truncated, and all cells will be aligned right.
 <p></div>
<dl><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="show(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>show</h4>
<pre>public&nbsp;void&nbsp;show(boolean&nbsp;truncate)</pre>
<div class="block">Displays the top 20 rows of <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> in a tabular form.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>truncate</code> - Whether truncate long strings. If true, strings more than 20 characters will
              be truncated and all cells will be aligned right
 <p></dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="show(int, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>show</h4>
<pre>public&nbsp;void&nbsp;show(int&nbsp;numRows,
        boolean&nbsp;truncate)</pre>
<div class="block">Displays the <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> in a tabular form. For example:
 <pre><code>
   year  month AVG('Adj Close) MAX('Adj Close)
   1980  12    0.503218        0.595103
   1981  01    0.523289        0.570307
   1982  02    0.436504        0.475256
   1983  03    0.410516        0.442194
   1984  04    0.450090        0.483521
 </code></pre></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>numRows</code> - Number of rows to show</dd><dd><code>truncate</code> - Whether truncate long strings. If true, strings more than 20 characters will
              be truncated and all cells will be aligned right
 <p></dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="repartition(int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>repartition</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;repartition(int&nbsp;numPartitions)</pre>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that has exactly <code>numPartitions</code> partitions.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>numPartitions</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="coalesce(int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>coalesce</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;coalesce(int&nbsp;numPartitions)</pre>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that has exactly <code>numPartitions</code> partitions.
 Similar to coalesce defined on an <code>RDD</code>, this operation results in a narrow dependency, e.g.
 if you go from 1000 partitions to 100 partitions, there will not be a shuffle, instead each of
 the 100 new partitions will claim 10 of the current partitions.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>numPartitions</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="transform(scala.Function1)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>transform</h4>
<pre>public&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;&nbsp;transform(scala.Function1&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;,<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;&gt;&nbsp;t)</pre>
<div class="block">Concise syntax for chaining custom transformations.
 <pre><code>
   def featurize(ds: Dataset[T]) = ...

   dataset
     .transform(featurize)
     .transform(...)
 </code></pre></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>t</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="filter(scala.Function1)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>filter</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;filter(scala.Function1&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,java.lang.Object&gt;&nbsp;func)</pre>
<div class="block">(Scala-specific)
 Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that only contains elements where <code>func</code> returns <code>true</code>.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>func</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="filter(org.apache.spark.api.java.function.FilterFunction)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>filter</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;filter(<a href="../../../../org/apache/spark/api/java/function/FilterFunction.html" title="interface in org.apache.spark.api.java.function">FilterFunction</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;func)</pre>
<div class="block">(Java-specific)
 Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that only contains elements where <code>func</code> returns <code>true</code>.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>func</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="map(scala.Function1, org.apache.spark.sql.Encoder)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>map</h4>
<pre>public&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;&nbsp;map(scala.Function1&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U&gt;&nbsp;func,
                 <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;evidence$2)</pre>
<div class="block">(Scala-specific)
 Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that contains the result of applying <code>func</code> to each element.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>func</code> - (undocumented)</dd><dd><code>evidence$2</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="map(org.apache.spark.api.java.function.MapFunction, org.apache.spark.sql.Encoder)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>map</h4>
<pre>public&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;&nbsp;map(<a href="../../../../org/apache/spark/api/java/function/MapFunction.html" title="interface in org.apache.spark.api.java.function">MapFunction</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U&gt;&nbsp;func,
                 <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;encoder)</pre>
<div class="block">(Java-specific)
 Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that contains the result of applying <code>func</code> to each element.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>func</code> - (undocumented)</dd><dd><code>encoder</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="mapPartitions(scala.Function1, org.apache.spark.sql.Encoder)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>mapPartitions</h4>
<pre>public&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;&nbsp;mapPartitions(scala.Function1&lt;scala.collection.Iterator&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;,scala.collection.Iterator&lt;U&gt;&gt;&nbsp;func,
                           <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;evidence$3)</pre>
<div class="block">(Scala-specific)
 Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that contains the result of applying <code>func</code> to each partition.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>func</code> - (undocumented)</dd><dd><code>evidence$3</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="mapPartitions(org.apache.spark.api.java.function.MapPartitionsFunction, org.apache.spark.sql.Encoder)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>mapPartitions</h4>
<pre>public&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;&nbsp;mapPartitions(<a href="../../../../org/apache/spark/api/java/function/MapPartitionsFunction.html" title="interface in org.apache.spark.api.java.function">MapPartitionsFunction</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U&gt;&nbsp;f,
                           <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;encoder)</pre>
<div class="block">(Java-specific)
 Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that contains the result of applying <code>func</code> to each partition.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>f</code> - (undocumented)</dd><dd><code>encoder</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="flatMap(scala.Function1, org.apache.spark.sql.Encoder)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>flatMap</h4>
<pre>public&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;&nbsp;flatMap(scala.Function1&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,scala.collection.TraversableOnce&lt;U&gt;&gt;&nbsp;func,
                     <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;evidence$4)</pre>
<div class="block">(Scala-specific)
 Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by first applying a function to all elements of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>,
 and then flattening the results.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>func</code> - (undocumented)</dd><dd><code>evidence$4</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="flatMap(org.apache.spark.api.java.function.FlatMapFunction, org.apache.spark.sql.Encoder)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>flatMap</h4>
<pre>public&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;&nbsp;flatMap(<a href="../../../../org/apache/spark/api/java/function/FlatMapFunction.html" title="interface in org.apache.spark.api.java.function">FlatMapFunction</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U&gt;&nbsp;f,
                     <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;encoder)</pre>
<div class="block">(Java-specific)
 Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by first applying a function to all elements of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>,
 and then flattening the results.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>f</code> - (undocumented)</dd><dd><code>encoder</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="foreach(scala.Function1)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>foreach</h4>
<pre>public&nbsp;void&nbsp;foreach(scala.Function1&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,scala.runtime.BoxedUnit&gt;&nbsp;func)</pre>
<div class="block">(Scala-specific)
 Runs <code>func</code> on each element of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>func</code> - (undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="foreach(org.apache.spark.api.java.function.ForeachFunction)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>foreach</h4>
<pre>public&nbsp;void&nbsp;foreach(<a href="../../../../org/apache/spark/api/java/function/ForeachFunction.html" title="interface in org.apache.spark.api.java.function">ForeachFunction</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;func)</pre>
<div class="block">(Java-specific)
 Runs <code>func</code> on each element of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>func</code> - (undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="foreachPartition(scala.Function1)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>foreachPartition</h4>
<pre>public&nbsp;void&nbsp;foreachPartition(scala.Function1&lt;scala.collection.Iterator&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;,scala.runtime.BoxedUnit&gt;&nbsp;func)</pre>
<div class="block">(Scala-specific)
 Runs <code>func</code> on each partition of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>func</code> - (undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="foreachPartition(org.apache.spark.api.java.function.ForeachPartitionFunction)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>foreachPartition</h4>
<pre>public&nbsp;void&nbsp;foreachPartition(<a href="../../../../org/apache/spark/api/java/function/ForeachPartitionFunction.html" title="interface in org.apache.spark.api.java.function">ForeachPartitionFunction</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;func)</pre>
<div class="block">(Java-specific)
 Runs <code>func</code> on each partition of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>func</code> - (undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="reduce(scala.Function2)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reduce</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&nbsp;reduce(scala.Function2&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;func)</pre>
<div class="block">(Scala-specific)
 Reduces the elements of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> using the specified binary function. The given <code>func</code>
 must be commutative and associative or the result may be non-deterministic.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>func</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="reduce(org.apache.spark.api.java.function.ReduceFunction)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reduce</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&nbsp;reduce(<a href="../../../../org/apache/spark/api/java/function/ReduceFunction.html" title="interface in org.apache.spark.api.java.function">ReduceFunction</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;func)</pre>
<div class="block">(Java-specific)
 Reduces the elements of this Dataset using the specified binary function.  The given <code>func</code>
 must be commutative and associative or the result may be non-deterministic.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>func</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="groupBy(scala.Function1, org.apache.spark.sql.Encoder)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>groupBy</h4>
<pre>public&nbsp;&lt;K&gt;&nbsp;<a href="../../../../org/apache/spark/sql/GroupedDataset.html" title="class in org.apache.spark.sql">GroupedDataset</a>&lt;K,<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;groupBy(scala.Function1&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,K&gt;&nbsp;func,
                              <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;K&gt;&nbsp;evidence$5)</pre>
<div class="block">(Scala-specific)
 Returns a <a href="../../../../org/apache/spark/sql/GroupedDataset.html" title="class in org.apache.spark.sql"><code>GroupedDataset</code></a> where the data is grouped by the given key <code>func</code>.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>func</code> - (undocumented)</dd><dd><code>evidence$5</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="groupBy(scala.collection.Seq)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>groupBy</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/GroupedDataset.html" title="class in org.apache.spark.sql">GroupedDataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>,<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;groupBy(scala.collection.Seq&lt;<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;cols)</pre>
<div class="block">Returns a <a href="../../../../org/apache/spark/sql/GroupedDataset.html" title="class in org.apache.spark.sql"><code>GroupedDataset</code></a> where the data is grouped by the given <a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expressions.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>cols</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="groupBy(org.apache.spark.api.java.function.MapFunction, org.apache.spark.sql.Encoder)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>groupBy</h4>
<pre>public&nbsp;&lt;K&gt;&nbsp;<a href="../../../../org/apache/spark/sql/GroupedDataset.html" title="class in org.apache.spark.sql">GroupedDataset</a>&lt;K,<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;groupBy(<a href="../../../../org/apache/spark/api/java/function/MapFunction.html" title="interface in org.apache.spark.api.java.function">MapFunction</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,K&gt;&nbsp;func,
                              <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;K&gt;&nbsp;encoder)</pre>
<div class="block">(Java-specific)
 Returns a <a href="../../../../org/apache/spark/sql/GroupedDataset.html" title="class in org.apache.spark.sql"><code>GroupedDataset</code></a> where the data is grouped by the given key <code>func</code>.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>func</code> - (undocumented)</dd><dd><code>encoder</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="select(scala.collection.Seq)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>select</h4>
<pre>protected&nbsp;<a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql">DataFrame</a>&nbsp;select(scala.collection.Seq&lt;<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;cols)</pre>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/DataFrame.html" title="class in org.apache.spark.sql"><code>DataFrame</code></a> by selecting a set of column based expressions.
 <pre><code>
   df.select($"colA", $"colB" + 1)
 </code></pre></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>cols</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="select(org.apache.spark.sql.TypedColumn, org.apache.spark.sql.Encoder)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>select</h4>
<pre>public&nbsp;&lt;U1&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U1&gt;&nbsp;select(<a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U1&gt;&nbsp;c1,
                      <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U1&gt;&nbsp;evidence$6)</pre>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by computing the given <a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expression for each element.
 <p>
 <pre><code>
   val ds = Seq(1, 2, 3).toDS()
   val newDS = ds.select(expr("value + 1").as[Int])
 </code></pre></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>c1</code> - (undocumented)</dd><dd><code>evidence$6</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="selectUntyped(scala.collection.Seq)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>selectUntyped</h4>
<pre>protected&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;?&gt;&nbsp;selectUntyped(scala.collection.Seq&lt;<a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;?,?&gt;&gt;&nbsp;columns)</pre>
<div class="block">Internal helper function for building typed selects that return tuples.  For simplicity and
 code reuse, we do this without the help of the type system and then use helper functions
 that cast appropriately for the user facing interface.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>columns</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="select(org.apache.spark.sql.TypedColumn, org.apache.spark.sql.TypedColumn)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>select</h4>
<pre>public&nbsp;&lt;U1,U2&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple2&lt;U1,U2&gt;&gt;&nbsp;select(<a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U1&gt;&nbsp;c1,
                                          <a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U2&gt;&nbsp;c2)</pre>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by computing the given <a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expressions for each element.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>c1</code> - (undocumented)</dd><dd><code>c2</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="select(org.apache.spark.sql.TypedColumn, org.apache.spark.sql.TypedColumn, org.apache.spark.sql.TypedColumn)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>select</h4>
<pre>public&nbsp;&lt;U1,U2,U3&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple3&lt;U1,U2,U3&gt;&gt;&nbsp;select(<a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U1&gt;&nbsp;c1,
                                                <a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U2&gt;&nbsp;c2,
                                                <a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U3&gt;&nbsp;c3)</pre>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by computing the given <a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expressions for each element.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>c1</code> - (undocumented)</dd><dd><code>c2</code> - (undocumented)</dd><dd><code>c3</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="select(org.apache.spark.sql.TypedColumn, org.apache.spark.sql.TypedColumn, org.apache.spark.sql.TypedColumn, org.apache.spark.sql.TypedColumn)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>select</h4>
<pre>public&nbsp;&lt;U1,U2,U3,U4&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple4&lt;U1,U2,U3,U4&gt;&gt;&nbsp;select(<a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U1&gt;&nbsp;c1,
                                                      <a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U2&gt;&nbsp;c2,
                                                      <a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U3&gt;&nbsp;c3,
                                                      <a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U4&gt;&nbsp;c4)</pre>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by computing the given <a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expressions for each element.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>c1</code> - (undocumented)</dd><dd><code>c2</code> - (undocumented)</dd><dd><code>c3</code> - (undocumented)</dd><dd><code>c4</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="select(org.apache.spark.sql.TypedColumn, org.apache.spark.sql.TypedColumn, org.apache.spark.sql.TypedColumn, org.apache.spark.sql.TypedColumn, org.apache.spark.sql.TypedColumn)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>select</h4>
<pre>public&nbsp;&lt;U1,U2,U3,U4,U5&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple5&lt;U1,U2,U3,U4,U5&gt;&gt;&nbsp;select(<a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U1&gt;&nbsp;c1,
                                                            <a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U2&gt;&nbsp;c2,
                                                            <a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U3&gt;&nbsp;c3,
                                                            <a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U4&gt;&nbsp;c4,
                                                            <a href="../../../../org/apache/spark/sql/TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U5&gt;&nbsp;c5)</pre>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by computing the given <a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expressions for each element.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>c1</code> - (undocumented)</dd><dd><code>c2</code> - (undocumented)</dd><dd><code>c3</code> - (undocumented)</dd><dd><code>c4</code> - (undocumented)</dd><dd><code>c5</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="sample(boolean, double, long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sample</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;sample(boolean&nbsp;withReplacement,
                double&nbsp;fraction,
                long&nbsp;seed)</pre>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by sampling a fraction of records.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>withReplacement</code> - (undocumented)</dd><dd><code>fraction</code> - (undocumented)</dd><dd><code>seed</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="sample(boolean, double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sample</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;sample(boolean&nbsp;withReplacement,
                double&nbsp;fraction)</pre>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by sampling a fraction of records, using a random seed.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>withReplacement</code> - (undocumented)</dd><dd><code>fraction</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="distinct()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>distinct</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;distinct()</pre>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that contains only the unique elements of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.
 <p>
 Note that, equality checking is performed directly on the encoded representation of the data
 and thus is not affected by a custom <code>equals</code> function defined on <code>T</code>.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="intersect(org.apache.spark.sql.Dataset)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>intersect</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;intersect(<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other)</pre>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that contains only the elements of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that are also
 present in <code>other</code>.
 <p>
 Note that, equality checking is performed directly on the encoded representation of the data
 and thus is not affected by a custom <code>equals</code> function defined on <code>T</code>.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>other</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="union(org.apache.spark.sql.Dataset)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>union</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;union(<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other)</pre>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that contains the elements of both this and the <code>other</code> <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>
 combined.
 <p>
 Note that, this function is not a typical set union operation, in that it does not eliminate
 duplicate items.  As such, it is analogous to <code>UNION ALL</code> in SQL.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>other</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="subtract(org.apache.spark.sql.Dataset)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>subtract</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;subtract(<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other)</pre>
<div class="block">Returns a new <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> where any elements present in <code>other</code> have been removed.
 <p>
 Note that, equality checking is performed directly on the encoded representation of the data
 and thus is not affected by a custom <code>equals</code> function defined on <code>T</code>.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>other</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="joinWith(org.apache.spark.sql.Dataset, org.apache.spark.sql.Column, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>joinWith</h4>
<pre>public&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U&gt;&gt;&nbsp;joinWith(<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;&nbsp;other,
                                      <a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;condition,
                                      java.lang.String&nbsp;joinType)</pre>
<div class="block">Joins this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> returning a <code>Tuple2</code> for each pair where <code>condition</code> evaluates to
 true.
 <p>
 This is similar to the relation <code>join</code> function with one important difference in the
 result schema. Since <code>joinWith</code> preserves objects present on either side of the join, the
 result schema is similarly nested into a tuple under the column names <code>_1</code> and <code>_2</code>.
 <p>
 This type of join can be useful both for preserving type-safety with the original object
 types as well as working with relational data where either side of the join has column
 names in common.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>other</code> - Right side of the join.</dd><dd><code>condition</code> - Join expression.</dd><dd><code>joinType</code> - One of: <code>inner</code>, <code>outer</code>, <code>left_outer</code>, <code>right_outer</code>, <code>leftsemi</code>.</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="joinWith(org.apache.spark.sql.Dataset, org.apache.spark.sql.Column)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>joinWith</h4>
<pre>public&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>,U&gt;&gt;&nbsp;joinWith(<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;&nbsp;other,
                                      <a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;condition)</pre>
<div class="block">Using inner equi-join to join this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> returning a <code>Tuple2</code> for each pair
 where <code>condition</code> evaluates to true.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>other</code> - Right side of the join.</dd><dd><code>condition</code> - Join expression.</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="first()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>first</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&nbsp;first()</pre>
<div class="block">Returns the first element in this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="collect()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>collect</h4>
<pre>public&nbsp;java.lang.Object&nbsp;collect()</pre>
<div class="block">Returns an array that contains all the elements in this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.
 <p>
 Running collect requires moving all the data into the application's driver process, and
 doing so on a very large <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> can crash the driver process with OutOfMemoryError.
 <p>
 For Java API, use <code>collectAsList</code>.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="collectAsList()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>collectAsList</h4>
<pre>public&nbsp;java.util.List&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;collectAsList()</pre>
<div class="block">Returns an array that contains all the elements in this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.
 <p>
 Running collect requires moving all the data into the application's driver process, and
 doing so on a very large <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> can crash the driver process with OutOfMemoryError.
 <p>
 For Java API, use <code>collectAsList</code>.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="take(int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>take</h4>
<pre>public&nbsp;java.lang.Object&nbsp;take(int&nbsp;num)</pre>
<div class="block">Returns the first <code>num</code> elements of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> as an array.
 <p>
 Running take requires moving data into the application's driver process, and doing so with
 a very large <code>num</code> can crash the driver process with OutOfMemoryError.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>num</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="takeAsList(int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>takeAsList</h4>
<pre>public&nbsp;java.util.List&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;takeAsList(int&nbsp;num)</pre>
<div class="block">Returns the first <code>num</code> elements of this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> as an array.
 <p>
 Running take requires moving data into the application's driver process, and doing so with
 a very large <code>num</code> can crash the driver process with OutOfMemoryError.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>num</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="persist()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>persist</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;persist()</pre>
<div class="block">Persist this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with the default storage level (<code>MEMORY_AND_DISK</code>).</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="cache()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cache</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;cache()</pre>
<div class="block">Persist this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with the default storage level (<code>MEMORY_AND_DISK</code>).</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="persist(org.apache.spark.storage.StorageLevel)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>persist</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;persist(<a href="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a>&nbsp;newLevel)</pre>
<div class="block">Persist this <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with the given storage level.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>newLevel</code> - One of: <code>MEMORY_ONLY</code>, <code>MEMORY_AND_DISK</code>, <code>MEMORY_ONLY_SER</code>,
                 <code>MEMORY_AND_DISK_SER</code>, <code>DISK_ONLY</code>, <code>MEMORY_ONLY_2</code>,
                 <code>MEMORY_AND_DISK_2</code>, etc.</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="unpersist(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>unpersist</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;unpersist(boolean&nbsp;blocking)</pre>
<div class="block">Mark the <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> as non-persistent, and remove all blocks for it from memory and disk.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>blocking</code> - Whether to block until all blocks are deleted.</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="unpersist()">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>unpersist</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;unpersist()</pre>
<div class="block">Mark the <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> as non-persistent, and remove all blocks for it from memory and disk.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/DataFrameWriter.html" title="class in org.apache.spark.sql"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/apache/spark/sql/DatasetHolder.html" title="class in org.apache.spark.sql"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/Dataset.html" target="_top">Frames</a></li>
<li><a href="Dataset.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../lib/api-javadocs.js"></script></body>
</html>
