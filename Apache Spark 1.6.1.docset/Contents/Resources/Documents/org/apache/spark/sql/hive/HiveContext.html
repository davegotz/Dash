<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_79) on Fri Feb 26 20:48:44 PST 2016 -->
<title>HiveContext</title>
<meta name="date" content="2016-02-26">
<link rel="stylesheet" type="text/css" href="../../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="HiveContext";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev Class</li>
<li><a href="../../../../../org/apache/spark/sql/hive/HiveContext.QueryExecution.html" title="class in org.apache.spark.sql.hive"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/sql/hive/HiveContext.html" target="_top">Frames</a></li>
<li><a href="HiveContext.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql.hive</div>
<h2 title="Class HiveContext" class="title">Class HiveContext</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li><a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">org.apache.spark.sql.SQLContext</a></li>
<li>
<ul class="inheritance">
<li>org.apache.spark.sql.hive.HiveContext</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable, <a href="../../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="strong">HiveContext</span>
extends <a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>
implements <a href="../../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></pre>
<div class="block">An instance of the Spark SQL execution engine that integrates with data stored in Hive.
 Configuration for Hive is read from hive-site.xml on the classpath.
 <p></div>
<dl><dt><span class="strong">Since:</span></dt>
  <dd>1.0.0</dd>
<dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../serialized-form.html#org.apache.spark.sql.hive.HiveContext">Serialized Form</a></dd></dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested_class_summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Nested Class Summary table, listing nested classes, and an explanation">
<caption><span>Nested Classes</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Class and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected class&nbsp;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.QueryExecution.html" title="class in org.apache.spark.sql.hive">HiveContext.QueryExecution</a></strong></code>
<div class="block">Extends QueryExecution with hive specific features.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="nested_classes_inherited_from_class_org.apache.spark.sql.SQLContext">
<!--   -->
</a>
<h3>Nested classes/interfaces inherited from class&nbsp;org.apache.spark.sql.<a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></h3>
<code><a href="../../../../../org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql">SQLContext.implicits$</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.SparkPlanner.html" title="class in org.apache.spark.sql">SQLContext.SparkPlanner</a></code></li>
</ul>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#HiveContext(org.apache.spark.api.java.JavaSparkContext)">HiveContext</a></strong>(<a href="../../../../../org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a>&nbsp;sc)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colOne"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#HiveContext(org.apache.spark.SparkContext)">HiveContext</a></strong>(<a href="../../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sc)</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#addJar(java.lang.String)">addJar</a></strong>(java.lang.String&nbsp;path)</code>
<div class="block">Add a jar to SQLContext</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#analyze(java.lang.String)">analyze</a></strong>(java.lang.String&nbsp;tableName)</code>
<div class="block">Analyzes the given table in the current database to generate statistics, which will be
 used in query optimizations.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected org.apache.spark.sql.catalyst.analysis.Analyzer</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#analyzer()">analyzer</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.apache.spark.sql.hive.HiveMetastoreCatalog</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#catalog()">catalog</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected org.apache.spark.sql.SQLConf</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#conf()">conf</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected scala.collection.immutable.Map&lt;java.lang.String,java.lang.String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#configure()">configure</a></strong>()</code>
<div class="block">Overridden by child classes that need to set configuration before the client init.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static <any></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#CONVERT_CTAS()">CONVERT_CTAS</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static <any></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#CONVERT_METASTORE_PARQUET_WITH_SCHEMA_MERGING()">CONVERT_METASTORE_PARQUET_WITH_SCHEMA_MERGING</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static <any></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#CONVERT_METASTORE_PARQUET()">CONVERT_METASTORE_PARQUET</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#convertCTAS()">convertCTAS</a></strong>()</code>
<div class="block">When true, a table created by a Hive CTAS statement (no USING clause) will be
 converted to a data source table, using the data source set by spark.sql.sources.default.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#convertMetastoreParquet()">convertMetastoreParquet</a></strong>()</code>
<div class="block">When true, enables an experimental feature where metastore tables that use the parquet SerDe
 are automatically converted to use the Spark SQL parquet table scan, instead of the Hive
 SerDe.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#convertMetastoreParquetWithSchemaMerging()">convertMetastoreParquetWithSchemaMerging</a></strong>()</code>
<div class="block">When true, also tries to merge possibly different but compatible Parquet schemas in different
 Parquet data files.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../../org/apache/spark/sql/hive/HiveContext.QueryExecution.html" title="class in org.apache.spark.sql.hive">HiveContext.QueryExecution</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#executePlan(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">executePlan</a></strong>(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;plan)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.apache.spark.sql.hive.client.ClientWrapper</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#executionHive()">executionHive</a></strong>()</code>
<div class="block">The copy of the hive client that is used for execution.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected org.apache.spark.sql.catalyst.analysis.FunctionRegistry</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#functionRegistry()">functionRegistry</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.apache.spark.sql.catalyst.ParserDialect</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#getSQLDialect()">getSQLDialect</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static <any></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#HIVE_EXECUTION_VERSION()">HIVE_EXECUTION_VERSION</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static <any></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#HIVE_METASTORE_BARRIER_PREFIXES()">HIVE_METASTORE_BARRIER_PREFIXES</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static <any></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#HIVE_METASTORE_JARS()">HIVE_METASTORE_JARS</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static <any></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#HIVE_METASTORE_SHARED_PREFIXES()">HIVE_METASTORE_SHARED_PREFIXES</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static <any></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#HIVE_METASTORE_VERSION()">HIVE_METASTORE_VERSION</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static <any></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#HIVE_THRIFT_SERVER_ASYNC()">HIVE_THRIFT_SERVER_ASYNC</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected org.apache.hadoop.hive.conf.HiveConf</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#hiveconf()">hiveconf</a></strong>()</code>
<div class="block">SQLConf and HiveConf contracts:</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static java.lang.String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#hiveExecutionVersion()">hiveExecutionVersion</a></strong>()</code>
<div class="block">The version of hive used internally by Spark SQL.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected scala.collection.Seq&lt;java.lang.String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#hiveMetastoreBarrierPrefixes()">hiveMetastoreBarrierPrefixes</a></strong>()</code>
<div class="block">A comma separated list of class prefixes that should explicitly be reloaded for each version
 of Hive that Spark SQL is communicating with.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected java.lang.String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#hiveMetastoreJars()">hiveMetastoreJars</a></strong>()</code>
<div class="block">The location of the jars that should be used to instantiate the HiveMetastoreClient.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected scala.collection.Seq&lt;java.lang.String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#hiveMetastoreSharedPrefixes()">hiveMetastoreSharedPrefixes</a></strong>()</code>
<div class="block">A comma separated list of class prefixes that should be loaded using the classloader that
 is shared between Spark SQL and a specific version of Hive.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected java.lang.String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#hiveMetastoreVersion()">hiveMetastoreVersion</a></strong>()</code>
<div class="block">The version of the hive client that will be used to communicate with the metastore.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#hiveThriftServerAsync()">hiveThriftServerAsync</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#hiveThriftServerSingleSession()">hiveThriftServerSingleSession</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#invalidateTable(java.lang.String)">invalidateTable</a></strong>(java.lang.String&nbsp;tableName)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.apache.spark.sql.hive.client.ClientInterface</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#metadataHive()">metadataHive</a></strong>()</code>
<div class="block">The copy of the Hive client that is used to retrieve metadata from the Hive MetaStore.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#newSession()">newSession</a></strong>()</code>
<div class="block">Returns a new HiveContext as new session, which will have separated SQLConf, UDF/UDAF,
 temporary tables and SessionState, but sharing the same CacheManager, IsolatedClientLoader
 and Hive client (both of execution and metadata) with existing HiveContext.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static scala.collection.immutable.Map&lt;java.lang.String,java.lang.String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#newTemporaryConfiguration()">newTemporaryConfiguration</a></strong>()</code>
<div class="block">Constructs a configuration for hive, where the metastore is located in a temp directory.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected org.apache.spark.sql.catalyst.plans.logical.LogicalPlan</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#parseSql(java.lang.String)">parseSql</a></strong>(java.lang.String&nbsp;sql)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../../org/apache/spark/sql/SQLContext.SparkPlanner.html" title="class in org.apache.spark.sql">SQLContext.SparkPlanner</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#planner()">planner</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected static scala.collection.Seq&lt;org.apache.spark.sql.types.AtomicType&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#primitiveTypes()">primitiveTypes</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#refreshTable(java.lang.String)">refreshTable</a></strong>(java.lang.String&nbsp;tableName)</code>
<div class="block">Invalidate and refresh all the cached the metadata of the given table.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected scala.collection.Seq&lt;java.lang.String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#runSqlHive(java.lang.String)">runSqlHive</a></strong>(java.lang.String&nbsp;sql)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#setConf(java.lang.String,%20java.lang.String)">setConf</a></strong>(java.lang.String&nbsp;key,
       java.lang.String&nbsp;value)</code>
<div class="block">Set the given Spark SQL configuration property.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected org.apache.hadoop.hive.ql.parse.VariableSubstitution</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#substitutor()">substitutor</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected static java.lang.String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#toHiveString(scala.Tuple2)">toHiveString</a></strong>(scala.Tuple2&lt;java.lang.Object,<a href="../../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</a>&gt;&nbsp;a)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected static java.lang.String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#toHiveStructString(scala.Tuple2)">toHiveStructString</a></strong>(scala.Tuple2&lt;java.lang.Object,<a href="../../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</a>&gt;&nbsp;a)</code>
<div class="block">Hive outputs fields of structs slightly differently than top level attributes.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.sql.SQLContext">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;org.apache.spark.sql.<a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></h3>
<code><a href="../../../../../org/apache/spark/sql/SQLContext.html#applySchema(org.apache.spark.api.java.JavaRDD,%20java.lang.Class)">applySchema</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#applySchema(org.apache.spark.api.java.JavaRDD,%20org.apache.spark.sql.types.StructType)">applySchema</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#applySchema(org.apache.spark.rdd.RDD,%20java.lang.Class)">applySchema</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#applySchema(org.apache.spark.rdd.RDD,%20org.apache.spark.sql.types.StructType)">applySchema</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#applySchemaToPythonRDD(org.apache.spark.rdd.RDD,%20java.lang.String)">applySchemaToPythonRDD</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#applySchemaToPythonRDD(org.apache.spark.rdd.RDD,%20org.apache.spark.sql.types.StructType)">applySchemaToPythonRDD</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#baseRelationToDataFrame(org.apache.spark.sql.sources.BaseRelation)">baseRelationToDataFrame</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#cacheManager()">cacheManager</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#cacheTable(java.lang.String)">cacheTable</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#clearActive()">clearActive</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#clearCache()">clearCache</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(org.apache.spark.api.java.JavaRDD,%20java.lang.Class)">createDataFrame</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(org.apache.spark.api.java.JavaRDD,%20org.apache.spark.sql.types.StructType)">createDataFrame</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(java.util.List,%20java.lang.Class)">createDataFrame</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(java.util.List,%20org.apache.spark.sql.types.StructType)">createDataFrame</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(org.apache.spark.rdd.RDD,%20java.lang.Class)">createDataFrame</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(org.apache.spark.rdd.RDD,%20scala.reflect.api.TypeTags.TypeTag)">createDataFrame</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(org.apache.spark.rdd.RDD,%20org.apache.spark.sql.types.StructType)">createDataFrame</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(scala.collection.Seq,%20scala.reflect.api.TypeTags.TypeTag)">createDataFrame</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#createDataset(java.util.List,%20org.apache.spark.sql.Encoder)">createDataset</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#createDataset(org.apache.spark.rdd.RDD,%20org.apache.spark.sql.Encoder)">createDataset</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#createDataset(scala.collection.Seq,%20org.apache.spark.sql.Encoder)">createDataset</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String,%20java.lang.String)">createExternalTable</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String,%20java.lang.String,%20java.util.Map)">createExternalTable</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String,%20java.lang.String,%20scala.collection.immutable.Map)">createExternalTable</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String,%20java.lang.String,%20java.lang.String)">createExternalTable</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String,%20java.lang.String,%20org.apache.spark.sql.types.StructType,%20java.util.Map)">createExternalTable</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String,%20java.lang.String,%20org.apache.spark.sql.types.StructType,%20scala.collection.immutable.Map)">createExternalTable</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#ddlParser()">ddlParser</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#dialectClassName()">dialectClassName</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#dropTempTable(java.lang.String)">dropTempTable</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#emptyDataFrame()">emptyDataFrame</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#emptyResult()">emptyResult</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#executeSql(java.lang.String)">executeSql</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#experimental()">experimental</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#getAllConfs()">getAllConfs</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#getConf(java.lang.String)">getConf</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#getConf(java.lang.String,%20java.lang.String)">getConf</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#getOrCreate(org.apache.spark.SparkContext)">getOrCreate</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#getSchema(java.lang.Class)">getSchema</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#implicits()">implicits</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#isCached(java.lang.String)">isCached</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#isRootContext()">isRootContext</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jdbc(java.lang.String,%20java.lang.String)">jdbc</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jdbc(java.lang.String,%20java.lang.String,%20java.lang.String[])">jdbc</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jdbc(java.lang.String,%20java.lang.String,%20java.lang.String,%20long,%20long,%20int)">jdbc</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String)">jsonFile</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String,%20double)">jsonFile</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String,%20org.apache.spark.sql.types.StructType)">jsonFile</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.api.java.JavaRDD)">jsonRDD</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.api.java.JavaRDD,%20double)">jsonRDD</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.api.java.JavaRDD,%20org.apache.spark.sql.types.StructType)">jsonRDD</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD)">jsonRDD</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD,%20double)">jsonRDD</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD,%20org.apache.spark.sql.types.StructType)">jsonRDD</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#listener()">listener</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#listenerManager()">listenerManager</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#load(java.lang.String)">load</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#load(java.lang.String,%20java.util.Map)">load</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#load(java.lang.String,%20scala.collection.immutable.Map)">load</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#load(java.lang.String,%20java.lang.String)">load</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#load(java.lang.String,%20org.apache.spark.sql.types.StructType,%20java.util.Map)">load</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#load(java.lang.String,%20org.apache.spark.sql.types.StructType,%20scala.collection.immutable.Map)">load</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#optimizer()">optimizer</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#parquetFile(scala.collection.Seq)">parquetFile</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#parquetFile(java.lang.String...)">parquetFile</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#parseDataType(java.lang.String)">parseDataType</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#prepareForExecution()">prepareForExecution</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#range(long)">range</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#range(long,%20long)">range</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#range(long,%20long,%20long,%20int)">range</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#read()">read</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#setActive(org.apache.spark.sql.SQLContext)">setActive</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#setConf(java.util.Properties)">setConf</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#sparkContext()">sparkContext</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#sql(java.lang.String)">sql</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#sqlParser()">sqlParser</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#table(java.lang.String)">table</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#tableNames()">tableNames</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#tableNames(java.lang.String)">tableNames</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#tables()">tables</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#tables(java.lang.String)">tables</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#udf()">udf</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#uncacheTable(java.lang.String)">uncacheTable</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.Logging">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.<a href="../../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></h3>
<code><a href="../../../../../org/apache/spark/Logging.html#initializeIfNecessary()">initializeIfNecessary</a>, <a href="../../../../../org/apache/spark/Logging.html#initializeLogging()">initializeLogging</a>, <a href="../../../../../org/apache/spark/Logging.html#isTraceEnabled()">isTraceEnabled</a>, <a href="../../../../../org/apache/spark/Logging.html#log_()">log_</a>, <a href="../../../../../org/apache/spark/Logging.html#log()">log</a>, <a href="../../../../../org/apache/spark/Logging.html#logDebug(scala.Function0)">logDebug</a>, <a href="../../../../../org/apache/spark/Logging.html#logDebug(scala.Function0,%20java.lang.Throwable)">logDebug</a>, <a href="../../../../../org/apache/spark/Logging.html#logError(scala.Function0)">logError</a>, <a href="../../../../../org/apache/spark/Logging.html#logError(scala.Function0,%20java.lang.Throwable)">logError</a>, <a href="../../../../../org/apache/spark/Logging.html#logInfo(scala.Function0)">logInfo</a>, <a href="../../../../../org/apache/spark/Logging.html#logInfo(scala.Function0,%20java.lang.Throwable)">logInfo</a>, <a href="../../../../../org/apache/spark/Logging.html#logName()">logName</a>, <a href="../../../../../org/apache/spark/Logging.html#logTrace(scala.Function0)">logTrace</a>, <a href="../../../../../org/apache/spark/Logging.html#logTrace(scala.Function0,%20java.lang.Throwable)">logTrace</a>, <a href="../../../../../org/apache/spark/Logging.html#logWarning(scala.Function0)">logWarning</a>, <a href="../../../../../org/apache/spark/Logging.html#logWarning(scala.Function0,%20java.lang.Throwable)">logWarning</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="HiveContext(org.apache.spark.SparkContext)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>HiveContext</h4>
<pre>public&nbsp;HiveContext(<a href="../../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sc)</pre>
</li>
</ul>
<a name="HiveContext(org.apache.spark.api.java.JavaSparkContext)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>HiveContext</h4>
<pre>public&nbsp;HiveContext(<a href="../../../../../org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a>&nbsp;sc)</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="hiveExecutionVersion()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>hiveExecutionVersion</h4>
<pre>public static&nbsp;java.lang.String&nbsp;hiveExecutionVersion()</pre>
<div class="block">The version of hive used internally by Spark SQL.</div>
</li>
</ul>
<a name="HIVE_METASTORE_VERSION()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>HIVE_METASTORE_VERSION</h4>
<pre>public static&nbsp;<any>&nbsp;HIVE_METASTORE_VERSION()</pre>
</li>
</ul>
<a name="HIVE_EXECUTION_VERSION()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>HIVE_EXECUTION_VERSION</h4>
<pre>public static&nbsp;<any>&nbsp;HIVE_EXECUTION_VERSION()</pre>
</li>
</ul>
<a name="HIVE_METASTORE_JARS()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>HIVE_METASTORE_JARS</h4>
<pre>public static&nbsp;<any>&nbsp;HIVE_METASTORE_JARS()</pre>
</li>
</ul>
<a name="CONVERT_METASTORE_PARQUET()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>CONVERT_METASTORE_PARQUET</h4>
<pre>public static&nbsp;<any>&nbsp;CONVERT_METASTORE_PARQUET()</pre>
</li>
</ul>
<a name="CONVERT_METASTORE_PARQUET_WITH_SCHEMA_MERGING()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>CONVERT_METASTORE_PARQUET_WITH_SCHEMA_MERGING</h4>
<pre>public static&nbsp;<any>&nbsp;CONVERT_METASTORE_PARQUET_WITH_SCHEMA_MERGING()</pre>
</li>
</ul>
<a name="CONVERT_CTAS()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>CONVERT_CTAS</h4>
<pre>public static&nbsp;<any>&nbsp;CONVERT_CTAS()</pre>
</li>
</ul>
<a name="HIVE_METASTORE_SHARED_PREFIXES()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>HIVE_METASTORE_SHARED_PREFIXES</h4>
<pre>public static&nbsp;<any>&nbsp;HIVE_METASTORE_SHARED_PREFIXES()</pre>
</li>
</ul>
<a name="HIVE_METASTORE_BARRIER_PREFIXES()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>HIVE_METASTORE_BARRIER_PREFIXES</h4>
<pre>public static&nbsp;<any>&nbsp;HIVE_METASTORE_BARRIER_PREFIXES()</pre>
</li>
</ul>
<a name="HIVE_THRIFT_SERVER_ASYNC()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>HIVE_THRIFT_SERVER_ASYNC</h4>
<pre>public static&nbsp;<any>&nbsp;HIVE_THRIFT_SERVER_ASYNC()</pre>
</li>
</ul>
<a name="newTemporaryConfiguration()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>newTemporaryConfiguration</h4>
<pre>public static&nbsp;scala.collection.immutable.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;newTemporaryConfiguration()</pre>
<div class="block">Constructs a configuration for hive, where the metastore is located in a temp directory.</div>
</li>
</ul>
<a name="primitiveTypes()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>primitiveTypes</h4>
<pre>protected static&nbsp;scala.collection.Seq&lt;org.apache.spark.sql.types.AtomicType&gt;&nbsp;primitiveTypes()</pre>
</li>
</ul>
<a name="toHiveString(scala.Tuple2)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>toHiveString</h4>
<pre>protected static&nbsp;java.lang.String&nbsp;toHiveString(scala.Tuple2&lt;java.lang.Object,<a href="../../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</a>&gt;&nbsp;a)</pre>
</li>
</ul>
<a name="toHiveStructString(scala.Tuple2)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>toHiveStructString</h4>
<pre>protected static&nbsp;java.lang.String&nbsp;toHiveStructString(scala.Tuple2&lt;java.lang.Object,<a href="../../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</a>&gt;&nbsp;a)</pre>
<div class="block">Hive outputs fields of structs slightly differently than top level attributes.</div>
</li>
</ul>
<a name="newSession()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>newSession</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</a>&nbsp;newSession()</pre>
<div class="block">Returns a new HiveContext as new session, which will have separated SQLConf, UDF/UDAF,
 temporary tables and SessionState, but sharing the same CacheManager, IsolatedClientLoader
 and Hive client (both of execution and metadata) with existing HiveContext.</div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../../org/apache/spark/sql/SQLContext.html#newSession()">newSession</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="convertMetastoreParquet()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>convertMetastoreParquet</h4>
<pre>protected&nbsp;boolean&nbsp;convertMetastoreParquet()</pre>
<div class="block">When true, enables an experimental feature where metastore tables that use the parquet SerDe
 are automatically converted to use the Spark SQL parquet table scan, instead of the Hive
 SerDe.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="convertMetastoreParquetWithSchemaMerging()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>convertMetastoreParquetWithSchemaMerging</h4>
<pre>protected&nbsp;boolean&nbsp;convertMetastoreParquetWithSchemaMerging()</pre>
<div class="block">When true, also tries to merge possibly different but compatible Parquet schemas in different
 Parquet data files.
 <p>
 This configuration is only effective when "spark.sql.hive.convertMetastoreParquet" is true.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="convertCTAS()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>convertCTAS</h4>
<pre>protected&nbsp;boolean&nbsp;convertCTAS()</pre>
<div class="block">When true, a table created by a Hive CTAS statement (no USING clause) will be
 converted to a data source table, using the data source set by spark.sql.sources.default.
 The table in CTAS statement will be converted when it meets any of the following conditions:
   - The CTAS does not specify any of a SerDe (ROW FORMAT SERDE), a File Format (STORED AS), or
     a Storage Hanlder (STORED BY), and the value of hive.default.fileformat in hive-site.xml
     is either TextFile or SequenceFile.
   - The CTAS statement specifies TextFile (STORED AS TEXTFILE) as the file format and no SerDe
     is specified (no ROW FORMAT SERDE clause).
   - The CTAS statement specifies SequenceFile (STORED AS SEQUENCEFILE) as the file format
     and no SerDe is specified (no ROW FORMAT SERDE clause).</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="hiveMetastoreVersion()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>hiveMetastoreVersion</h4>
<pre>protected&nbsp;java.lang.String&nbsp;hiveMetastoreVersion()</pre>
<div class="block">The version of the hive client that will be used to communicate with the metastore.  Note that
 this does not necessarily need to be the same version of Hive that is used internally by
 Spark SQL for execution.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="hiveMetastoreJars()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>hiveMetastoreJars</h4>
<pre>protected&nbsp;java.lang.String&nbsp;hiveMetastoreJars()</pre>
<div class="block">The location of the jars that should be used to instantiate the HiveMetastoreClient.  This
 property can be one of three options:
  - a classpath in the standard format for both hive and hadoop.
  - builtin - attempt to discover the jars that were used to load Spark SQL and use those. This
              option is only valid when using the execution version of Hive.
  - maven - download the correct version of hive on demand from maven.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="hiveMetastoreSharedPrefixes()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>hiveMetastoreSharedPrefixes</h4>
<pre>protected&nbsp;scala.collection.Seq&lt;java.lang.String&gt;&nbsp;hiveMetastoreSharedPrefixes()</pre>
<div class="block">A comma separated list of class prefixes that should be loaded using the classloader that
 is shared between Spark SQL and a specific version of Hive. An example of classes that should
 be shared is JDBC drivers that are needed to talk to the metastore. Other classes that need
 to be shared are those that interact with classes that are already shared.  For example,
 custom appenders that are used by log4j.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="hiveMetastoreBarrierPrefixes()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>hiveMetastoreBarrierPrefixes</h4>
<pre>protected&nbsp;scala.collection.Seq&lt;java.lang.String&gt;&nbsp;hiveMetastoreBarrierPrefixes()</pre>
<div class="block">A comma separated list of class prefixes that should explicitly be reloaded for each version
 of Hive that Spark SQL is communicating with.  For example, Hive UDFs that are declared in a
 prefix that typically would be shared (i.e. org.apache.spark.*)</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="hiveThriftServerAsync()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>hiveThriftServerAsync</h4>
<pre>protected&nbsp;boolean&nbsp;hiveThriftServerAsync()</pre>
</li>
</ul>
<a name="hiveThriftServerSingleSession()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>hiveThriftServerSingleSession</h4>
<pre>protected&nbsp;boolean&nbsp;hiveThriftServerSingleSession()</pre>
</li>
</ul>
<a name="substitutor()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>substitutor</h4>
<pre>protected&nbsp;org.apache.hadoop.hive.ql.parse.VariableSubstitution&nbsp;substitutor()</pre>
</li>
</ul>
<a name="executionHive()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>executionHive</h4>
<pre>protected&nbsp;org.apache.spark.sql.hive.client.ClientWrapper&nbsp;executionHive()</pre>
<div class="block">The copy of the hive client that is used for execution.  Currently this must always be
 Hive 13 as this is the version of Hive that is packaged with Spark SQL.  This copy of the
 client is used for execution related tasks like registering temporary functions or ensuring
 that the ThreadLocal SessionState is correctly populated.  This copy of Hive is *not* used
 for storing persistent metadata, and only point to a dummy metastore in a temporary directory.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="metadataHive()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>metadataHive</h4>
<pre>protected&nbsp;org.apache.spark.sql.hive.client.ClientInterface&nbsp;metadataHive()</pre>
<div class="block">The copy of the Hive client that is used to retrieve metadata from the Hive MetaStore.
 The version of the Hive client that is used here must match the metastore that is configured
 in the hive-site.xml file.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="parseSql(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parseSql</h4>
<pre>protected&nbsp;org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;parseSql(java.lang.String&nbsp;sql)</pre>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../../org/apache/spark/sql/SQLContext.html#parseSql(java.lang.String)">parseSql</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></code></dd>
</dl>
</li>
</ul>
<a name="executePlan(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>executePlan</h4>
<pre>protected&nbsp;<a href="../../../../../org/apache/spark/sql/hive/HiveContext.QueryExecution.html" title="class in org.apache.spark.sql.hive">HiveContext.QueryExecution</a>&nbsp;executePlan(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;plan)</pre>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../../org/apache/spark/sql/SQLContext.html#executePlan(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">executePlan</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></code></dd>
</dl>
</li>
</ul>
<a name="refreshTable(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>refreshTable</h4>
<pre>public&nbsp;void&nbsp;refreshTable(java.lang.String&nbsp;tableName)</pre>
<div class="block">Invalidate and refresh all the cached the metadata of the given table. For performance reasons,
 Spark SQL or the external data source library it uses might cache certain metadata about a
 table, such as the location of blocks. When those change outside of Spark SQL, users should
 call this function to invalidate the cache.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>tableName</code> - (undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="invalidateTable(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>invalidateTable</h4>
<pre>protected&nbsp;void&nbsp;invalidateTable(java.lang.String&nbsp;tableName)</pre>
</li>
</ul>
<a name="analyze(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>analyze</h4>
<pre>public&nbsp;void&nbsp;analyze(java.lang.String&nbsp;tableName)</pre>
<div class="block">Analyzes the given table in the current database to generate statistics, which will be
 used in query optimizations.
 <p>
 Right now, it only supports Hive tables and it only updates the size of a Hive table
 in the Hive metastore.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>tableName</code> - (undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.2.0</dd></dl>
</li>
</ul>
<a name="setConf(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setConf</h4>
<pre>public&nbsp;void&nbsp;setConf(java.lang.String&nbsp;key,
           java.lang.String&nbsp;value)</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../../org/apache/spark/sql/SQLContext.html#setConf(java.lang.String,%20java.lang.String)">SQLContext</a></code></strong></div>
<div class="block">Set the given Spark SQL configuration property.
 <p></div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../../org/apache/spark/sql/SQLContext.html#setConf(java.lang.String,%20java.lang.String)">setConf</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>key</code> - (undocumented)</dd><dd><code>value</code> - (undocumented)</dd></dl>
</li>
</ul>
<a name="catalog()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>catalog</h4>
<pre>protected&nbsp;org.apache.spark.sql.hive.HiveMetastoreCatalog&nbsp;catalog()</pre>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../../org/apache/spark/sql/SQLContext.html#catalog()">catalog</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></code></dd>
</dl>
</li>
</ul>
<a name="functionRegistry()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>functionRegistry</h4>
<pre>protected&nbsp;org.apache.spark.sql.catalyst.analysis.FunctionRegistry&nbsp;functionRegistry()</pre>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../../org/apache/spark/sql/SQLContext.html#functionRegistry()">functionRegistry</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></code></dd>
</dl>
</li>
</ul>
<a name="analyzer()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>analyzer</h4>
<pre>protected&nbsp;org.apache.spark.sql.catalyst.analysis.Analyzer&nbsp;analyzer()</pre>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../../org/apache/spark/sql/SQLContext.html#analyzer()">analyzer</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></code></dd>
</dl>
</li>
</ul>
<a name="configure()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>configure</h4>
<pre>protected&nbsp;scala.collection.immutable.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;configure()</pre>
<div class="block">Overridden by child classes that need to set configuration before the client init.</div>
</li>
</ul>
<a name="hiveconf()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>hiveconf</h4>
<pre>protected&nbsp;org.apache.hadoop.hive.conf.HiveConf&nbsp;hiveconf()</pre>
<div class="block">SQLConf and HiveConf contracts:
 <p>
 1. create a new SessionState for each HiveContext
 2. when the Hive session is first initialized, params in HiveConf will get picked up by the
    SQLConf.  Additionally, any properties set by set() or a SET command inside sql() will be
    set in the SQLConf *as well as* in the HiveConf.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="conf()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>conf</h4>
<pre>protected&nbsp;org.apache.spark.sql.SQLConf&nbsp;conf()</pre>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../../org/apache/spark/sql/SQLContext.html#conf()">conf</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>Spark SQL configuration</dd></dl>
</li>
</ul>
<a name="getSQLDialect()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getSQLDialect</h4>
<pre>protected&nbsp;org.apache.spark.sql.catalyst.ParserDialect&nbsp;getSQLDialect()</pre>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../../org/apache/spark/sql/SQLContext.html#getSQLDialect()">getSQLDialect</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></code></dd>
</dl>
</li>
</ul>
<a name="runSqlHive(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>runSqlHive</h4>
<pre>protected&nbsp;scala.collection.Seq&lt;java.lang.String&gt;&nbsp;runSqlHive(java.lang.String&nbsp;sql)</pre>
</li>
</ul>
<a name="planner()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>planner</h4>
<pre>protected&nbsp;<a href="../../../../../org/apache/spark/sql/SQLContext.SparkPlanner.html" title="class in org.apache.spark.sql">SQLContext.SparkPlanner</a>&nbsp;planner()</pre>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../../org/apache/spark/sql/SQLContext.html#planner()">planner</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></code></dd>
</dl>
</li>
</ul>
<a name="addJar(java.lang.String)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>addJar</h4>
<pre>protected&nbsp;void&nbsp;addJar(java.lang.String&nbsp;path)</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../../org/apache/spark/sql/SQLContext.html#addJar(java.lang.String)">SQLContext</a></code></strong></div>
<div class="block">Add a jar to SQLContext</div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../../org/apache/spark/sql/SQLContext.html#addJar(java.lang.String)">addJar</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>path</code> - (undocumented)</dd></dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev Class</li>
<li><a href="../../../../../org/apache/spark/sql/hive/HiveContext.QueryExecution.html" title="class in org.apache.spark.sql.hive"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/sql/hive/HiveContext.html" target="_top">Frames</a></li>
<li><a href="HiveContext.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../../lib/api-javadocs.js"></script></body>
</html>
