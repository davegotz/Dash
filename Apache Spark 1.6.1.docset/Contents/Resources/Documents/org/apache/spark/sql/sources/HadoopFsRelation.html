<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_79) on Fri Feb 26 20:48:46 PST 2016 -->
<title>HadoopFsRelation</title>
<meta name="date" content="2016-02-26">
<link rel="stylesheet" type="text/css" href="../../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="HadoopFsRelation";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/spark/sql/sources/GreaterThanOrEqual.html" title="class in org.apache.spark.sql.sources"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.FakeFileStatus.html" title="class in org.apache.spark.sql.sources"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/sql/sources/HadoopFsRelation.html" target="_top">Frames</a></li>
<li><a href="HadoopFsRelation.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql.sources</div>
<h2 title="Class HadoopFsRelation" class="title">Class HadoopFsRelation</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li><a href="../../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">org.apache.spark.sql.sources.BaseRelation</a></li>
<li>
<ul class="inheritance">
<li>org.apache.spark.sql.sources.HadoopFsRelation</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd><a href="../../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a>, org.apache.spark.sql.execution.FileRelation</dd>
</dl>
<hr>
<br>
<pre>public abstract class <span class="strong">HadoopFsRelation</span>
extends <a href="../../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</a>
implements org.apache.spark.sql.execution.FileRelation, <a href="../../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></pre>
<div class="block">::Experimental::
 A <a href="../../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources"><code>BaseRelation</code></a> that provides much of the common code required for relations that store their
 data to an HDFS compatible filesystem.
 <p>
 For the read path, similar to <a href="../../../../../org/apache/spark/sql/sources/PrunedFilteredScan.html" title="interface in org.apache.spark.sql.sources"><code>PrunedFilteredScan</code></a>, it can eliminate unneeded columns and
 filter using selected predicates before producing an RDD containing all matching tuples as
 <code>Row</code> objects. In addition, when reading from Hive style partitioned tables stored in file
 systems, it's able to discover partitioning information from the paths of input directories, and
 perform partition pruning before start reading the data. Subclasses of <a href="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#HadoopFsRelation()"><code>HadoopFsRelation()</code></a>
 must override one of the four <code>buildScan</code> methods to implement the read path.
 <p>
 For the write path, it provides the ability to write to both non-partitioned and partitioned
 tables.  Directory layout of the partitioned tables is compatible with Hive.
 <p></div>
<dl><dt><span class="strong">Since:</span></dt>
  <dd>1.4.0</dd></dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested_class_summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Nested Class Summary table, listing nested classes, and an explanation">
<caption><span>Nested Classes</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Class and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.FakeFileStatus.html" title="class in org.apache.spark.sql.sources">HadoopFsRelation.FakeFileStatus</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.FakeFileStatus$.html" title="class in org.apache.spark.sql.sources">HadoopFsRelation.FakeFileStatus$</a></strong></code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#HadoopFsRelation()">HadoopFsRelation</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colOne"><code><strong><a href="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#HadoopFsRelation(scala.collection.immutable.Map)">HadoopFsRelation</a></strong>(scala.collection.immutable.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;parameters)</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#buildScan(org.apache.hadoop.fs.FileStatus[])">buildScan</a></strong>(org.apache.hadoop.fs.FileStatus[]&nbsp;inputFiles)</code>
<div class="block">For a non-partitioned relation, this method builds an <code>RDD[Row]</code> containing all rows within
 this relation.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#buildScan(java.lang.String[],%20org.apache.hadoop.fs.FileStatus[])">buildScan</a></strong>(java.lang.String[]&nbsp;requiredColumns,
         org.apache.hadoop.fs.FileStatus[]&nbsp;inputFiles)</code>
<div class="block">For a non-partitioned relation, this method builds an <code>RDD[Row]</code> containing all rows within
 this relation.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#buildScan(java.lang.String[],%20org.apache.spark.sql.sources.Filter[],%20org.apache.hadoop.fs.FileStatus[])">buildScan</a></strong>(java.lang.String[]&nbsp;requiredColumns,
         <a href="../../../../../org/apache/spark/sql/sources/Filter.html" title="class in org.apache.spark.sql.sources">Filter</a>[]&nbsp;filters,
         org.apache.hadoop.fs.FileStatus[]&nbsp;inputFiles)</code>
<div class="block">For a non-partitioned relation, this method builds an <code>RDD[Row]</code> containing all rows within
 this relation.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected scala.collection.mutable.LinkedHashSet&lt;org.apache.hadoop.fs.FileStatus&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#cachedLeafStatuses()">cachedLeafStatuses</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>abstract <a href="../../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#dataSchema()">dataSchema</a></strong>()</code>
<div class="block">Specifies schema of actual data files.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.lang.String[]</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#inputFiles()">inputFiles</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.hadoop.fs.FileStatus[]</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#listLeafFiles(org.apache.hadoop.fs.FileSystem,%20org.apache.hadoop.fs.FileStatus)">listLeafFiles</a></strong>(org.apache.hadoop.fs.FileSystem&nbsp;fs,
             org.apache.hadoop.fs.FileStatus&nbsp;status)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static scala.collection.mutable.LinkedHashSet&lt;org.apache.hadoop.fs.FileStatus&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#listLeafFilesInParallel(java.lang.String[],%20org.apache.hadoop.conf.Configuration,%20org.apache.spark.SparkContext)">listLeafFilesInParallel</a></strong>(java.lang.String[]&nbsp;paths,
                       org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
                       <a href="../../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sparkContext)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#partitionColumns()">partitionColumns</a></strong>()</code>
<div class="block">Partition columns.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>abstract java.lang.String[]</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#paths()">paths</a></strong>()</code>
<div class="block">Paths of this relation.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>abstract <a href="../../../../../org/apache/spark/sql/sources/OutputWriterFactory.html" title="class in org.apache.spark.sql.sources">OutputWriterFactory</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#prepareJobForWrite(org.apache.hadoop.mapreduce.Job)">prepareJobForWrite</a></strong>(org.apache.hadoop.mapreduce.Job&nbsp;job)</code>
<div class="block">Prepares a write job and returns an <a href="../../../../../org/apache/spark/sql/sources/OutputWriterFactory.html" title="class in org.apache.spark.sql.sources"><code>OutputWriterFactory</code></a>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#schema()">schema</a></strong>()</code>
<div class="block">Schema of this relation.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>long</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#sizeInBytes()">sizeInBytes</a></strong>()</code>
<div class="block">Returns an estimated size of this relation in bytes.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.lang.String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#toString()">toString</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>scala.Option&lt;<a href="../../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.html#userDefinedPartitionColumns()">userDefinedPartitionColumns</a></strong>()</code>
<div class="block">Optional user defined partition columns.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.sql.sources.BaseRelation">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;org.apache.spark.sql.sources.<a href="../../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</a></h3>
<code><a href="../../../../../org/apache/spark/sql/sources/BaseRelation.html#needConversion()">needConversion</a>, <a href="../../../../../org/apache/spark/sql/sources/BaseRelation.html#sqlContext()">sqlContext</a>, <a href="../../../../../org/apache/spark/sql/sources/BaseRelation.html#unhandledFilters(org.apache.spark.sql.sources.Filter[])">unhandledFilters</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.Logging">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.<a href="../../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></h3>
<code><a href="../../../../../org/apache/spark/Logging.html#initializeIfNecessary()">initializeIfNecessary</a>, <a href="../../../../../org/apache/spark/Logging.html#initializeLogging()">initializeLogging</a>, <a href="../../../../../org/apache/spark/Logging.html#isTraceEnabled()">isTraceEnabled</a>, <a href="../../../../../org/apache/spark/Logging.html#log_()">log_</a>, <a href="../../../../../org/apache/spark/Logging.html#log()">log</a>, <a href="../../../../../org/apache/spark/Logging.html#logDebug(scala.Function0)">logDebug</a>, <a href="../../../../../org/apache/spark/Logging.html#logDebug(scala.Function0,%20java.lang.Throwable)">logDebug</a>, <a href="../../../../../org/apache/spark/Logging.html#logError(scala.Function0)">logError</a>, <a href="../../../../../org/apache/spark/Logging.html#logError(scala.Function0,%20java.lang.Throwable)">logError</a>, <a href="../../../../../org/apache/spark/Logging.html#logInfo(scala.Function0)">logInfo</a>, <a href="../../../../../org/apache/spark/Logging.html#logInfo(scala.Function0,%20java.lang.Throwable)">logInfo</a>, <a href="../../../../../org/apache/spark/Logging.html#logName()">logName</a>, <a href="../../../../../org/apache/spark/Logging.html#logTrace(scala.Function0)">logTrace</a>, <a href="../../../../../org/apache/spark/Logging.html#logTrace(scala.Function0,%20java.lang.Throwable)">logTrace</a>, <a href="../../../../../org/apache/spark/Logging.html#logWarning(scala.Function0)">logWarning</a>, <a href="../../../../../org/apache/spark/Logging.html#logWarning(scala.Function0,%20java.lang.Throwable)">logWarning</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="HadoopFsRelation()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>HadoopFsRelation</h4>
<pre>public&nbsp;HadoopFsRelation()</pre>
</li>
</ul>
<a name="HadoopFsRelation(scala.collection.immutable.Map)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>HadoopFsRelation</h4>
<pre>public&nbsp;HadoopFsRelation(scala.collection.immutable.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;parameters)</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="listLeafFiles(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.FileStatus)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>listLeafFiles</h4>
<pre>public static&nbsp;org.apache.hadoop.fs.FileStatus[]&nbsp;listLeafFiles(org.apache.hadoop.fs.FileSystem&nbsp;fs,
                                              org.apache.hadoop.fs.FileStatus&nbsp;status)</pre>
</li>
</ul>
<a name="listLeafFilesInParallel(java.lang.String[], org.apache.hadoop.conf.Configuration, org.apache.spark.SparkContext)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>listLeafFilesInParallel</h4>
<pre>public static&nbsp;scala.collection.mutable.LinkedHashSet&lt;org.apache.hadoop.fs.FileStatus&gt;&nbsp;listLeafFilesInParallel(java.lang.String[]&nbsp;paths,
                                                                                              org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
                                                                                              <a href="../../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sparkContext)</pre>
</li>
</ul>
<a name="toString()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>toString</h4>
<pre>public&nbsp;java.lang.String&nbsp;toString()</pre>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code>toString</code>&nbsp;in class&nbsp;<code>java.lang.Object</code></dd>
</dl>
</li>
</ul>
<a name="cachedLeafStatuses()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cachedLeafStatuses</h4>
<pre>protected&nbsp;scala.collection.mutable.LinkedHashSet&lt;org.apache.hadoop.fs.FileStatus&gt;&nbsp;cachedLeafStatuses()</pre>
</li>
</ul>
<a name="paths()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>paths</h4>
<pre>public abstract&nbsp;java.lang.String[]&nbsp;paths()</pre>
<div class="block">Paths of this relation.  For partitioned relations, it should be root directories
 of all partition directories.
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.4.0</dd></dl>
</li>
</ul>
<a name="inputFiles()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>inputFiles</h4>
<pre>public&nbsp;java.lang.String[]&nbsp;inputFiles()</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>inputFiles</code>&nbsp;in interface&nbsp;<code>org.apache.spark.sql.execution.FileRelation</code></dd>
</dl>
</li>
</ul>
<a name="sizeInBytes()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sizeInBytes</h4>
<pre>public&nbsp;long&nbsp;sizeInBytes()</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../../org/apache/spark/sql/sources/BaseRelation.html#sizeInBytes()">BaseRelation</a></code></strong></div>
<div class="block">Returns an estimated size of this relation in bytes. This information is used by the planner
 to decide when it is safe to broadcast a relation and can be overridden by sources that
 know the size ahead of time. By default, the system will assume that tables are too
 large to broadcast. This method will be called multiple times during query planning
 and thus should not perform expensive operations for each invocation.
 <p>
 Note that it is always better to overestimate size than underestimate, because underestimation
 could lead to execution plans that are suboptimal (i.e. broadcasting a very large table).
 <p></div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../../org/apache/spark/sql/sources/BaseRelation.html#sizeInBytes()">sizeInBytes</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="partitionColumns()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>partitionColumns</h4>
<pre>public final&nbsp;<a href="../../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;partitionColumns()</pre>
<div class="block">Partition columns.  Can be either defined by <code>userDefinedPartitionColumns</code> or automatically
 discovered.  Note that they should always be nullable.
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.4.0</dd></dl>
</li>
</ul>
<a name="userDefinedPartitionColumns()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>userDefinedPartitionColumns</h4>
<pre>public&nbsp;scala.Option&lt;<a href="../../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&gt;&nbsp;userDefinedPartitionColumns()</pre>
<div class="block">Optional user defined partition columns.
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.4.0</dd></dl>
</li>
</ul>
<a name="schema()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>schema</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema()</pre>
<div class="block">Schema of this relation.  It consists of columns appearing in <code>dataSchema</code> and all partition
 columns not appearing in <code>dataSchema</code>.
 <p></div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/spark/sql/sources/BaseRelation.html#schema()">schema</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.4.0</dd></dl>
</li>
</ul>
<a name="dataSchema()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>dataSchema</h4>
<pre>public abstract&nbsp;<a href="../../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;dataSchema()</pre>
<div class="block">Specifies schema of actual data files.  For partitioned relations, if one or more partitioned
 columns are contained in the data files, they should also appear in <code>dataSchema</code>.
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.4.0</dd></dl>
</li>
</ul>
<a name="buildScan(org.apache.hadoop.fs.FileStatus[])">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>buildScan</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;buildScan(org.apache.hadoop.fs.FileStatus[]&nbsp;inputFiles)</pre>
<div class="block">For a non-partitioned relation, this method builds an <code>RDD[Row]</code> containing all rows within
 this relation. For partitioned relations, this method is called for each selected partition,
 and builds an <code>RDD[Row]</code> containing all rows within that single partition.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>inputFiles</code> - For a non-partitioned relation, it contains paths of all data files in the
        relation. For a partitioned relation, it contains paths of all data files in a single
        selected partition.
 <p></dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.4.0</dd></dl>
</li>
</ul>
<a name="buildScan(java.lang.String[], org.apache.hadoop.fs.FileStatus[])">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>buildScan</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;buildScan(java.lang.String[]&nbsp;requiredColumns,
                 org.apache.hadoop.fs.FileStatus[]&nbsp;inputFiles)</pre>
<div class="block">For a non-partitioned relation, this method builds an <code>RDD[Row]</code> containing all rows within
 this relation. For partitioned relations, this method is called for each selected partition,
 and builds an <code>RDD[Row]</code> containing all rows within that single partition.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>requiredColumns</code> - Required columns.</dd><dd><code>inputFiles</code> - For a non-partitioned relation, it contains paths of all data files in the
        relation. For a partitioned relation, it contains paths of all data files in a single
        selected partition.
 <p></dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.4.0</dd></dl>
</li>
</ul>
<a name="buildScan(java.lang.String[], org.apache.spark.sql.sources.Filter[], org.apache.hadoop.fs.FileStatus[])">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>buildScan</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;buildScan(java.lang.String[]&nbsp;requiredColumns,
                 <a href="../../../../../org/apache/spark/sql/sources/Filter.html" title="class in org.apache.spark.sql.sources">Filter</a>[]&nbsp;filters,
                 org.apache.hadoop.fs.FileStatus[]&nbsp;inputFiles)</pre>
<div class="block">For a non-partitioned relation, this method builds an <code>RDD[Row]</code> containing all rows within
 this relation. For partitioned relations, this method is called for each selected partition,
 and builds an <code>RDD[Row]</code> containing all rows within that single partition.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>requiredColumns</code> - Required columns.</dd><dd><code>filters</code> - Candidate filters to be pushed down. The actual filter should be the conjunction
        of all <code>filters</code>.  The pushed down filters are currently purely an optimization as they
        will all be evaluated again. This means it is safe to use them with methods that produce
        false positives such as filtering partitions based on a bloom filter.</dd><dd><code>inputFiles</code> - For a non-partitioned relation, it contains paths of all data files in the
        relation. For a partitioned relation, it contains paths of all data files in a single
        selected partition.
 <p></dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.4.0</dd></dl>
</li>
</ul>
<a name="prepareJobForWrite(org.apache.hadoop.mapreduce.Job)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>prepareJobForWrite</h4>
<pre>public abstract&nbsp;<a href="../../../../../org/apache/spark/sql/sources/OutputWriterFactory.html" title="class in org.apache.spark.sql.sources">OutputWriterFactory</a>&nbsp;prepareJobForWrite(org.apache.hadoop.mapreduce.Job&nbsp;job)</pre>
<div class="block">Prepares a write job and returns an <a href="../../../../../org/apache/spark/sql/sources/OutputWriterFactory.html" title="class in org.apache.spark.sql.sources"><code>OutputWriterFactory</code></a>.  Client side job preparation can
 be put here.  For example, user defined output committer can be configured here
 by setting the output committer class in the conf of spark.sql.sources.outputCommitterClass.
 <p>
 Note that the only side effect expected here is mutating <code>job</code> via its setters.  Especially,
 Spark SQL caches <a href="../../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources"><code>BaseRelation</code></a> instances for performance, mutating relation internal states
 may cause unexpected behaviors.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>job</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.4.0</dd></dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/spark/sql/sources/GreaterThanOrEqual.html" title="class in org.apache.spark.sql.sources"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../../org/apache/spark/sql/sources/HadoopFsRelation.FakeFileStatus.html" title="class in org.apache.spark.sql.sources"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/sql/sources/HadoopFsRelation.html" target="_top">Frames</a></li>
<li><a href="HadoopFsRelation.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../../lib/api-javadocs.js"></script></body>
</html>
