<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_79) on Fri Feb 26 20:48:46 PST 2016 -->
<title>JdbcRDD</title>
<meta name="date" content="2016-02-26">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="JdbcRDD";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/apache/spark/rdd/JdbcRDD.ConnectionFactory.html" title="interface in org.apache.spark.rdd"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/rdd/JdbcRDD.html" target="_top">Frames</a></li>
<li><a href="JdbcRDD.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.rdd</div>
<h2 title="Class JdbcRDD" class="title">Class JdbcRDD&lt;T&gt;</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">org.apache.spark.rdd.RDD</a>&lt;T&gt;</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.rdd.JdbcRDD&lt;T&gt;</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable, <a href="../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="strong">JdbcRDD&lt;T&gt;</span>
extends <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;
implements <a href="../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></pre>
<div class="block">An RDD that executes an SQL query on a JDBC connection and reads results.
 For usage example, see test case JdbcRDDSuite.
 <p>
 param:  getConnection a function that returns an open Connection.
   The RDD takes care of closing the connection.
 param:  sql the text of the query.
   The query must contain two ? placeholders for parameters used to partition the results.
   E.g. "select title, author from books where ? <= id and id <= ?"
 param:  lowerBound the minimum value of the first placeholder
 param:  upperBound the maximum value of the second placeholder
   The lower and upper bounds are inclusive.
 param:  numPartitions the number of partitions.
   Given a lowerBound of 1, an upperBound of 20, and a numPartitions of 2,
   the query would be executed twice, once with (1, 10) and once with (11, 20)
 param:  mapRow a function from a ResultSet to a single row of the desired result type(s).
   This should only call getInt, getString, etc; the RDD takes care of calling next.
   The default maps a ResultSet to an array of Object.</div>
<dl><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../serialized-form.html#org.apache.spark.rdd.JdbcRDD">Serialized Form</a></dd></dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested_class_summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Nested Class Summary table, listing nested classes, and an explanation">
<caption><span>Nested Classes</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Class and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static interface&nbsp;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/JdbcRDD.ConnectionFactory.html" title="interface in org.apache.spark.rdd">JdbcRDD.ConnectionFactory</a></strong></code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../org/apache/spark/rdd/JdbcRDD.html#JdbcRDD(org.apache.spark.SparkContext,%20scala.Function0,%20java.lang.String,%20long,%20long,%20int,%20scala.Function1,%20scala.reflect.ClassTag)">JdbcRDD</a></strong>(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sc,
       scala.Function0&lt;java.sql.Connection&gt;&nbsp;getConnection,
       java.lang.String&nbsp;sql,
       long&nbsp;lowerBound,
       long&nbsp;upperBound,
       int&nbsp;numPartitions,
       scala.Function1&lt;java.sql.ResultSet,<a href="../../../../org/apache/spark/rdd/JdbcRDD.html" title="type parameter in JdbcRDD">T</a>&gt;&nbsp;mapRow,
       scala.reflect.ClassTag&lt;<a href="../../../../org/apache/spark/rdd/JdbcRDD.html" title="type parameter in JdbcRDD">T</a>&gt;&nbsp;evidence$1)</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>scala.collection.Iterator&lt;<a href="../../../../org/apache/spark/rdd/JdbcRDD.html" title="type parameter in JdbcRDD">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/JdbcRDD.html#compute(org.apache.spark.Partition,%20org.apache.spark.TaskContext)">compute</a></strong>(<a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>&nbsp;thePart,
       <a href="../../../../org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</a>&nbsp;context)</code>
<div class="block">:: DeveloperApi ::
 Implemented by subclasses to compute a given partition.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;java.lang.Object[]&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/JdbcRDD.html#create(org.apache.spark.api.java.JavaSparkContext,%20org.apache.spark.rdd.JdbcRDD.ConnectionFactory,%20java.lang.String,%20long,%20long,%20int)">create</a></strong>(<a href="../../../../org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a>&nbsp;sc,
      <a href="../../../../org/apache/spark/rdd/JdbcRDD.ConnectionFactory.html" title="interface in org.apache.spark.rdd">JdbcRDD.ConnectionFactory</a>&nbsp;connectionFactory,
      java.lang.String&nbsp;sql,
      long&nbsp;lowerBound,
      long&nbsp;upperBound,
      int&nbsp;numPartitions)</code>
<div class="block">Create an RDD that executes an SQL query on a JDBC connection and reads results.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static &lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;T&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/JdbcRDD.html#create(org.apache.spark.api.java.JavaSparkContext,%20org.apache.spark.rdd.JdbcRDD.ConnectionFactory,%20java.lang.String,%20long,%20long,%20int,%20org.apache.spark.api.java.function.Function)">create</a></strong>(<a href="../../../../org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a>&nbsp;sc,
      <a href="../../../../org/apache/spark/rdd/JdbcRDD.ConnectionFactory.html" title="interface in org.apache.spark.rdd">JdbcRDD.ConnectionFactory</a>&nbsp;connectionFactory,
      java.lang.String&nbsp;sql,
      long&nbsp;lowerBound,
      long&nbsp;upperBound,
      int&nbsp;numPartitions,
      <a href="../../../../org/apache/spark/api/java/function/Function.html" title="interface in org.apache.spark.api.java.function">Function</a>&lt;java.sql.ResultSet,T&gt;&nbsp;mapRow)</code>
<div class="block">Create an RDD that executes an SQL query on a JDBC connection and reads results.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>[]</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/JdbcRDD.html#getPartitions()">getPartitions</a></strong>()</code>
<div class="block">Implemented by subclasses to return the set of partitions in this RDD.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static java.lang.Object[]</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/rdd/JdbcRDD.html#resultSetToObjectArray(java.sql.ResultSet)">resultSetToObjectArray</a></strong>(java.sql.ResultSet&nbsp;rs)</code>&nbsp;</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.rdd.RDD">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;org.apache.spark.rdd.<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></h3>
<code><a href="../../../../org/apache/spark/rdd/RDD.html#aggregate(U,%20scala.Function2,%20scala.Function2,%20scala.reflect.ClassTag)">aggregate</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#cache()">cache</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#cartesian(org.apache.spark.rdd.RDD,%20scala.reflect.ClassTag)">cartesian</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#checkpoint()">checkpoint</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#checkpointData()">checkpointData</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#clearDependencies()">clearDependencies</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#coalesce(int,%20boolean,%20scala.math.Ordering)">coalesce</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#collect()">collect</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#collect(scala.PartialFunction,%20scala.reflect.ClassTag)">collect</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#context()">context</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#count()">count</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#countApprox(long,%20double)">countApprox</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#countApproxDistinct(double)">countApproxDistinct</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#countApproxDistinct(int,%20int)">countApproxDistinct</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#countByValue(scala.math.Ordering)">countByValue</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#countByValueApprox(long,%20double,%20scala.math.Ordering)">countByValueApprox</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#creationSite()">creationSite</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#dependencies()">dependencies</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#distinct()">distinct</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#distinct(int,%20scala.math.Ordering)">distinct</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#doubleRDDToDoubleRDDFunctions(org.apache.spark.rdd.RDD)">doubleRDDToDoubleRDDFunctions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#filter(scala.Function1)">filter</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#filterWith(scala.Function1,%20scala.Function2)">filterWith</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#first()">first</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#firstParent(scala.reflect.ClassTag)">firstParent</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#flatMap(scala.Function1,%20scala.reflect.ClassTag)">flatMap</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#flatMapWith(scala.Function1,%20boolean,%20scala.Function2,%20scala.reflect.ClassTag)">flatMapWith</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#fold(T,%20scala.Function2)">fold</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#foreach(scala.Function1)">foreach</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#foreachPartition(scala.Function1)">foreachPartition</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#foreachWith(scala.Function1,%20scala.Function2)">foreachWith</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#getCheckpointFile()">getCheckpointFile</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#getDependencies()">getDependencies</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#getNumPartitions()">getNumPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#getPreferredLocations(org.apache.spark.Partition)">getPreferredLocations</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#getStorageLevel()">getStorageLevel</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#glom()">glom</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#groupBy(scala.Function1,%20scala.reflect.ClassTag)">groupBy</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#groupBy(scala.Function1,%20int,%20scala.reflect.ClassTag)">groupBy</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#groupBy(scala.Function1,%20org.apache.spark.Partitioner,%20scala.reflect.ClassTag,%20scala.math.Ordering)">groupBy</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#id()">id</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#intersection(org.apache.spark.rdd.RDD)">intersection</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#intersection(org.apache.spark.rdd.RDD,%20int)">intersection</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#intersection(org.apache.spark.rdd.RDD,%20org.apache.spark.Partitioner,%20scala.math.Ordering)">intersection</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#isCheckpointed()">isCheckpointed</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#isEmpty()">isEmpty</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#iterator(org.apache.spark.Partition,%20org.apache.spark.TaskContext)">iterator</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#keyBy(scala.Function1)">keyBy</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#localCheckpoint()">localCheckpoint</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#map(scala.Function1,%20scala.reflect.ClassTag)">map</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#mapPartitions(scala.Function1,%20boolean,%20scala.reflect.ClassTag)">mapPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#mapPartitionsWithContext(scala.Function2,%20boolean,%20scala.reflect.ClassTag)">mapPartitionsWithContext</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#mapPartitionsWithIndex(scala.Function2,%20boolean,%20scala.reflect.ClassTag)">mapPartitionsWithIndex</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#mapPartitionsWithSplit(scala.Function2,%20boolean,%20scala.reflect.ClassTag)">mapPartitionsWithSplit</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#mapWith(scala.Function1,%20boolean,%20scala.Function2,%20scala.reflect.ClassTag)">mapWith</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#max(scala.math.Ordering)">max</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#min(scala.math.Ordering)">min</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#name()">name</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#numericRDDToDoubleRDDFunctions(org.apache.spark.rdd.RDD,%20scala.math.Numeric)">numericRDDToDoubleRDDFunctions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#parent(int,%20scala.reflect.ClassTag)">parent</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#partitioner()">partitioner</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#partitions()">partitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#persist()">persist</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#persist(org.apache.spark.storage.StorageLevel)">persist</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#pipe(scala.collection.Seq,%20scala.collection.Map,%20scala.Function1,%20scala.Function2,%20boolean)">pipe</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#pipe(java.lang.String)">pipe</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#pipe(java.lang.String,%20scala.collection.Map)">pipe</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#preferredLocations(org.apache.spark.Partition)">preferredLocations</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#randomSplit(double[],%20long)">randomSplit</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#rddToAsyncRDDActions(org.apache.spark.rdd.RDD,%20scala.reflect.ClassTag)">rddToAsyncRDDActions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#rddToOrderedRDDFunctions(org.apache.spark.rdd.RDD,%20scala.math.Ordering,%20scala.reflect.ClassTag,%20scala.reflect.ClassTag)">rddToOrderedRDDFunctions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#rddToPairRDDFunctions(org.apache.spark.rdd.RDD,%20scala.reflect.ClassTag,%20scala.reflect.ClassTag,%20scala.math.Ordering)">rddToPairRDDFunctions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#rddToSequenceFileRDDFunctions(org.apache.spark.rdd.RDD,%20scala.reflect.ClassTag,%20scala.reflect.ClassTag,%20,%20)">rddToSequenceFileRDDFunctions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#reduce(scala.Function2)">reduce</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#repartition(int,%20scala.math.Ordering)">repartition</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#sample(boolean,%20double,%20long)">sample</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#saveAsObjectFile(java.lang.String)">saveAsObjectFile</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#saveAsTextFile(java.lang.String)">saveAsTextFile</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#saveAsTextFile(java.lang.String,%20java.lang.Class)">saveAsTextFile</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#scope()">scope</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#setName(java.lang.String)">setName</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#sortBy(scala.Function1,%20boolean,%20int,%20scala.math.Ordering,%20scala.reflect.ClassTag)">sortBy</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#sparkContext()">sparkContext</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#subtract(org.apache.spark.rdd.RDD)">subtract</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#subtract(org.apache.spark.rdd.RDD,%20int)">subtract</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#subtract(org.apache.spark.rdd.RDD,%20org.apache.spark.Partitioner,%20scala.math.Ordering)">subtract</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#take(int)">take</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#takeOrdered(int,%20scala.math.Ordering)">takeOrdered</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#takeSample(boolean,%20int,%20long)">takeSample</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#toArray()">toArray</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#toDebugString()">toDebugString</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#toJavaRDD()">toJavaRDD</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#toLocalIterator()">toLocalIterator</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#top(int,%20scala.math.Ordering)">top</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#toString()">toString</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#treeAggregate(U,%20scala.Function2,%20scala.Function2,%20int,%20scala.reflect.ClassTag)">treeAggregate</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#treeReduce(scala.Function2,%20int)">treeReduce</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#union(org.apache.spark.rdd.RDD)">union</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#unpersist(boolean)">unpersist</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zip(org.apache.spark.rdd.RDD,%20scala.reflect.ClassTag)">zip</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD,%20boolean,%20scala.Function2,%20scala.reflect.ClassTag,%20scala.reflect.ClassTag)">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD,%20scala.Function2,%20scala.reflect.ClassTag,%20scala.reflect.ClassTag)">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD,%20org.apache.spark.rdd.RDD,%20boolean,%20scala.Function3,%20scala.reflect.ClassTag,%20scala.reflect.ClassTag,%20scala.reflect.ClassTag)">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD,%20org.apache.spark.rdd.RDD,%20scala.Function3,%20scala.reflect.ClassTag,%20scala.reflect.ClassTag,%20scala.reflect.ClassTag)">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD,%20org.apache.spark.rdd.RDD,%20org.apache.spark.rdd.RDD,%20boolean,%20scala.Function4,%20scala.reflect.ClassTag,%20scala.reflect.ClassTag,%20scala.reflect.ClassTag,%20scala.reflect.ClassTag)">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD,%20org.apache.spark.rdd.RDD,%20org.apache.spark.rdd.RDD,%20scala.Function4,%20scala.reflect.ClassTag,%20scala.reflect.ClassTag,%20scala.reflect.ClassTag,%20scala.reflect.ClassTag)">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipWithIndex()">zipWithIndex</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipWithUniqueId()">zipWithUniqueId</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.Logging">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.<a href="../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></h3>
<code><a href="../../../../org/apache/spark/Logging.html#initializeIfNecessary()">initializeIfNecessary</a>, <a href="../../../../org/apache/spark/Logging.html#initializeLogging()">initializeLogging</a>, <a href="../../../../org/apache/spark/Logging.html#isTraceEnabled()">isTraceEnabled</a>, <a href="../../../../org/apache/spark/Logging.html#log_()">log_</a>, <a href="../../../../org/apache/spark/Logging.html#log()">log</a>, <a href="../../../../org/apache/spark/Logging.html#logDebug(scala.Function0)">logDebug</a>, <a href="../../../../org/apache/spark/Logging.html#logDebug(scala.Function0,%20java.lang.Throwable)">logDebug</a>, <a href="../../../../org/apache/spark/Logging.html#logError(scala.Function0)">logError</a>, <a href="../../../../org/apache/spark/Logging.html#logError(scala.Function0,%20java.lang.Throwable)">logError</a>, <a href="../../../../org/apache/spark/Logging.html#logInfo(scala.Function0)">logInfo</a>, <a href="../../../../org/apache/spark/Logging.html#logInfo(scala.Function0,%20java.lang.Throwable)">logInfo</a>, <a href="../../../../org/apache/spark/Logging.html#logName()">logName</a>, <a href="../../../../org/apache/spark/Logging.html#logTrace(scala.Function0)">logTrace</a>, <a href="../../../../org/apache/spark/Logging.html#logTrace(scala.Function0,%20java.lang.Throwable)">logTrace</a>, <a href="../../../../org/apache/spark/Logging.html#logWarning(scala.Function0)">logWarning</a>, <a href="../../../../org/apache/spark/Logging.html#logWarning(scala.Function0,%20java.lang.Throwable)">logWarning</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="JdbcRDD(org.apache.spark.SparkContext, scala.Function0, java.lang.String, long, long, int, scala.Function1, scala.reflect.ClassTag)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>JdbcRDD</h4>
<pre>public&nbsp;JdbcRDD(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sc,
       scala.Function0&lt;java.sql.Connection&gt;&nbsp;getConnection,
       java.lang.String&nbsp;sql,
       long&nbsp;lowerBound,
       long&nbsp;upperBound,
       int&nbsp;numPartitions,
       scala.Function1&lt;java.sql.ResultSet,<a href="../../../../org/apache/spark/rdd/JdbcRDD.html" title="type parameter in JdbcRDD">T</a>&gt;&nbsp;mapRow,
       scala.reflect.ClassTag&lt;<a href="../../../../org/apache/spark/rdd/JdbcRDD.html" title="type parameter in JdbcRDD">T</a>&gt;&nbsp;evidence$1)</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="resultSetToObjectArray(java.sql.ResultSet)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>resultSetToObjectArray</h4>
<pre>public static&nbsp;java.lang.Object[]&nbsp;resultSetToObjectArray(java.sql.ResultSet&nbsp;rs)</pre>
</li>
</ul>
<a name="create(org.apache.spark.api.java.JavaSparkContext, org.apache.spark.rdd.JdbcRDD.ConnectionFactory, java.lang.String, long, long, int, org.apache.spark.api.java.function.Function)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>create</h4>
<pre>public static&nbsp;&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;T&gt;&nbsp;create(<a href="../../../../org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a>&nbsp;sc,
                    <a href="../../../../org/apache/spark/rdd/JdbcRDD.ConnectionFactory.html" title="interface in org.apache.spark.rdd">JdbcRDD.ConnectionFactory</a>&nbsp;connectionFactory,
                    java.lang.String&nbsp;sql,
                    long&nbsp;lowerBound,
                    long&nbsp;upperBound,
                    int&nbsp;numPartitions,
                    <a href="../../../../org/apache/spark/api/java/function/Function.html" title="interface in org.apache.spark.api.java.function">Function</a>&lt;java.sql.ResultSet,T&gt;&nbsp;mapRow)</pre>
<div class="block">Create an RDD that executes an SQL query on a JDBC connection and reads results.
 For usage example, see test case JavaAPISuite.testJavaJdbcRDD.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>connectionFactory</code> - a factory that returns an open Connection.
   The RDD takes care of closing the connection.</dd><dd><code>sql</code> - the text of the query.
   The query must contain two ? placeholders for parameters used to partition the results.
   E.g. "select title, author from books where ? <= id and id <= ?"</dd><dd><code>lowerBound</code> - the minimum value of the first placeholder</dd><dd><code>upperBound</code> - the maximum value of the second placeholder
   The lower and upper bounds are inclusive.</dd><dd><code>numPartitions</code> - the number of partitions.
   Given a lowerBound of 1, an upperBound of 20, and a numPartitions of 2,
   the query would be executed twice, once with (1, 10) and once with (11, 20)</dd><dd><code>mapRow</code> - a function from a ResultSet to a single row of the desired result type(s).
   This should only call getInt, getString, etc; the RDD takes care of calling next.
   The default maps a ResultSet to an array of Object.</dd><dd><code>sc</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="create(org.apache.spark.api.java.JavaSparkContext, org.apache.spark.rdd.JdbcRDD.ConnectionFactory, java.lang.String, long, long, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>create</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;java.lang.Object[]&gt;&nbsp;create(<a href="../../../../org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a>&nbsp;sc,
                                 <a href="../../../../org/apache/spark/rdd/JdbcRDD.ConnectionFactory.html" title="interface in org.apache.spark.rdd">JdbcRDD.ConnectionFactory</a>&nbsp;connectionFactory,
                                 java.lang.String&nbsp;sql,
                                 long&nbsp;lowerBound,
                                 long&nbsp;upperBound,
                                 int&nbsp;numPartitions)</pre>
<div class="block">Create an RDD that executes an SQL query on a JDBC connection and reads results. Each row is
 converted into a <code>Object</code> array. For usage example, see test case JavaAPISuite.testJavaJdbcRDD.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>connectionFactory</code> - a factory that returns an open Connection.
   The RDD takes care of closing the connection.</dd><dd><code>sql</code> - the text of the query.
   The query must contain two ? placeholders for parameters used to partition the results.
   E.g. "select title, author from books where ? <= id and id <= ?"</dd><dd><code>lowerBound</code> - the minimum value of the first placeholder</dd><dd><code>upperBound</code> - the maximum value of the second placeholder
   The lower and upper bounds are inclusive.</dd><dd><code>numPartitions</code> - the number of partitions.
   Given a lowerBound of 1, an upperBound of 20, and a numPartitions of 2,
   the query would be executed twice, once with (1, 10) and once with (11, 20)</dd><dd><code>sc</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="getPartitions()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getPartitions</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>[]&nbsp;getPartitions()</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#getPartitions()">RDD</a></code></strong></div>
<div class="block">Implemented by subclasses to return the set of partitions in this RDD. This method will only
 be called once, so it is safe to implement a time-consuming computation in it.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#getPartitions()">getPartitions</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../org/apache/spark/rdd/JdbcRDD.html" title="type parameter in JdbcRDD">T</a>&gt;</code></dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="compute(org.apache.spark.Partition, org.apache.spark.TaskContext)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>compute</h4>
<pre>public&nbsp;scala.collection.Iterator&lt;<a href="../../../../org/apache/spark/rdd/JdbcRDD.html" title="type parameter in JdbcRDD">T</a>&gt;&nbsp;compute(<a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>&nbsp;thePart,
                                   <a href="../../../../org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</a>&nbsp;context)</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#compute(org.apache.spark.Partition,%20org.apache.spark.TaskContext)">RDD</a></code></strong></div>
<div class="block">:: DeveloperApi ::
 Implemented by subclasses to compute a given partition.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#compute(org.apache.spark.Partition,%20org.apache.spark.TaskContext)">compute</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../org/apache/spark/rdd/JdbcRDD.html" title="type parameter in JdbcRDD">T</a>&gt;</code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>thePart</code> - (undocumented)</dd><dd><code>context</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/apache/spark/rdd/JdbcRDD.ConnectionFactory.html" title="interface in org.apache.spark.rdd"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/rdd/JdbcRDD.html" target="_top">Frames</a></li>
<li><a href="JdbcRDD.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../lib/api-javadocs.js"></script></body>
</html>
